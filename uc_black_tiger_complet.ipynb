{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47181978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51592d8b",
   "metadata": {},
   "source": [
    "### Adresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0db84a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_adr_i = [(0,2), (2,5), (13,20),\n",
    "            (110,135), (257,262), (165,190), (160,165),\n",
    "            (262,263), (263,267), (268,272)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65c7c950",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_adr_n = [\"code province\", \"code commune\", \"code unité pop\",\n",
    "            \"entité singulière\", \"code postal\", \"nom abrégé voie\",\"code voie\",\n",
    "            \"type num\", \"début num\", \"fin num\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2af7205",
   "metadata": {},
   "outputs": [],
   "source": [
    "adr_p02 = r\"P02\\TRAM.P02.D240630.G240703\" # P02\n",
    "adr_all = r\"caj_esp_072024\\TRAM.P01-52.D240630.G240703\" #  P01-52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3cd6896",
   "metadata": {},
   "outputs": [],
   "source": [
    "adr = pd.read_fwf(adr_all, colspecs=col_adr_i, header=None, encoding='ISO-8859-1', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0f6be4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adr.columns = col_adr_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a2d796f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code province</th>\n",
       "      <th>code commune</th>\n",
       "      <th>code unité pop</th>\n",
       "      <th>entité singulière</th>\n",
       "      <th>code postal</th>\n",
       "      <th>nom abrégé voie</th>\n",
       "      <th>code voie</th>\n",
       "      <th>type num</th>\n",
       "      <th>début num</th>\n",
       "      <th>fin num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>0001701</td>\n",
       "      <td>ALEGRIA-DULANTZI</td>\n",
       "      <td>01240</td>\n",
       "      <td>TORRONDOA</td>\n",
       "      <td>01001</td>\n",
       "      <td>1</td>\n",
       "      <td>0001</td>\n",
       "      <td>0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>0001701</td>\n",
       "      <td>ALEGRIA-DULANTZI</td>\n",
       "      <td>01240</td>\n",
       "      <td>AÑUA BIDEA</td>\n",
       "      <td>01002</td>\n",
       "      <td>1</td>\n",
       "      <td>0009</td>\n",
       "      <td>0039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>0001701</td>\n",
       "      <td>ALEGRIA-DULANTZI</td>\n",
       "      <td>01240</td>\n",
       "      <td>AÑUA BIDEA</td>\n",
       "      <td>01002</td>\n",
       "      <td>2</td>\n",
       "      <td>0004</td>\n",
       "      <td>0024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>0001701</td>\n",
       "      <td>ALEGRIA-DULANTZI</td>\n",
       "      <td>01240</td>\n",
       "      <td>GOIKOLANDA</td>\n",
       "      <td>01003</td>\n",
       "      <td>2</td>\n",
       "      <td>0002</td>\n",
       "      <td>0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>0001701</td>\n",
       "      <td>ALEGRIA-DULANTZI</td>\n",
       "      <td>01240</td>\n",
       "      <td>TORREALDEA</td>\n",
       "      <td>01004</td>\n",
       "      <td>1</td>\n",
       "      <td>0005</td>\n",
       "      <td>0005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code province code commune code unité pop entité singulière code postal  \\\n",
       "0            01          001        0001701  ALEGRIA-DULANTZI       01240   \n",
       "1            01          001        0001701  ALEGRIA-DULANTZI       01240   \n",
       "2            01          001        0001701  ALEGRIA-DULANTZI       01240   \n",
       "3            01          001        0001701  ALEGRIA-DULANTZI       01240   \n",
       "4            01          001        0001701  ALEGRIA-DULANTZI       01240   \n",
       "\n",
       "  nom abrégé voie code voie type num début num fin num  \n",
       "0       TORRONDOA     01001        1      0001    0027  \n",
       "1      AÑUA BIDEA     01002        1      0009    0039  \n",
       "2      AÑUA BIDEA     01002        2      0004    0024  \n",
       "3      GOIKOLANDA     01003        2      0002    0010  \n",
       "4      TORREALDEA     01004        1      0005    0005  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea875b34",
   "metadata": {},
   "source": [
    "### Noms de voies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20e93c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_vias_i = [(0,2), (2,5), (22,27), (27,32), \n",
    "               (32,33), (33,83), (83,108)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3363edc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_vias_n = [\"code province\", \"code commune\", \"code voie\", \n",
    "               \"type de voie\", \"pos type voie\", \"nom de voie\", \"nom court\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c70ef6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vias_p02 = r\"P02\\VIAS.P02.D240630.G240703\" # P02\n",
    "vias_all = r\"caj_esp_072024\\VIAS.P01-52.D240630.G240703\" # P01-52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac0d6b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vias = pd.read_fwf(vias_all, colspecs=cols_vias_i, header=None, encoding='ISO-8859-1', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d4bc4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vias.columns = cols_vias_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dfb50ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code province</th>\n",
       "      <th>code commune</th>\n",
       "      <th>code voie</th>\n",
       "      <th>type de voie</th>\n",
       "      <th>pos type voie</th>\n",
       "      <th>nom de voie</th>\n",
       "      <th>nom court</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001</td>\n",
       "      <td>KALE</td>\n",
       "      <td>0</td>\n",
       "      <td>TORRONDOA</td>\n",
       "      <td>TORRONDOA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01002</td>\n",
       "      <td>KALE</td>\n",
       "      <td>0</td>\n",
       "      <td>AÑUA BIDEA</td>\n",
       "      <td>AÑUA BIDEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01003</td>\n",
       "      <td>KALE</td>\n",
       "      <td>0</td>\n",
       "      <td>GOIKOLANDA</td>\n",
       "      <td>GOIKOLANDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01004</td>\n",
       "      <td>KALE</td>\n",
       "      <td>0</td>\n",
       "      <td>TORREALDEA</td>\n",
       "      <td>TORREALDEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01005</td>\n",
       "      <td>CALLE</td>\n",
       "      <td>0</td>\n",
       "      <td>NUESTRA SEÑORA DE AIALA</td>\n",
       "      <td>NUESTRA SEÑORA DE AIALA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code province code commune code voie type de voie pos type voie  \\\n",
       "0            01          001     01001         KALE             0   \n",
       "1            01          001     01002         KALE             0   \n",
       "2            01          001     01003         KALE             0   \n",
       "3            01          001     01004         KALE             0   \n",
       "4            01          001     01005        CALLE             0   \n",
       "\n",
       "               nom de voie                nom court  \n",
       "0                TORRONDOA                TORRONDOA  \n",
       "1               AÑUA BIDEA               AÑUA BIDEA  \n",
       "2               GOIKOLANDA               GOIKOLANDA  \n",
       "3               TORREALDEA               TORREALDEA  \n",
       "4  NUESTRA SEÑORA DE AIALA  NUESTRA SEÑORA DE AIALA  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vias.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b873f7",
   "metadata": {},
   "source": [
    "### préparation corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c665165",
   "metadata": {},
   "outputs": [],
   "source": [
    "adr_m_vias = pd.merge(adr, vias, on=[\"code province\", \"code commune\", \"code voie\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd39a658",
   "metadata": {},
   "outputs": [],
   "source": [
    "adr_m_vias[\"fin num\"] = adr_m_vias[\"fin num\"].astype(int)\n",
    "adr_m_vias[\"fin num\"] = adr_m_vias[\"fin num\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bc72f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "adr_m_vias[\"adresses\"] = (adr_m_vias[\"fin num\"]+\"<>\"+\n",
    "                         adr_m_vias[\"type de voie\"]+\" \"+\n",
    "                         adr_m_vias[\"nom de voie\"]+\"<>\"+\n",
    "                         adr_m_vias[\"code postal\"]+\"<>\"+\n",
    "                         adr_m_vias[\"entité singulière\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7035f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "adr_m_vias[\"labels\"] = \"num rue cp ville\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "521e344d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fin num</th>\n",
       "      <th>type de voie</th>\n",
       "      <th>nom de voie</th>\n",
       "      <th>code postal</th>\n",
       "      <th>entité singulière</th>\n",
       "      <th>adresses</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>KALE</td>\n",
       "      <td>TORRONDOA</td>\n",
       "      <td>01240</td>\n",
       "      <td>ALEGRIA-DULANTZI</td>\n",
       "      <td>27&lt;&gt;KALE TORRONDOA&lt;&gt;01240&lt;&gt;ALEGRIA-DULANTZI</td>\n",
       "      <td>num rue cp ville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>KALE</td>\n",
       "      <td>AÑUA BIDEA</td>\n",
       "      <td>01240</td>\n",
       "      <td>ALEGRIA-DULANTZI</td>\n",
       "      <td>39&lt;&gt;KALE AÑUA BIDEA&lt;&gt;01240&lt;&gt;ALEGRIA-DULANTZI</td>\n",
       "      <td>num rue cp ville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>KALE</td>\n",
       "      <td>AÑUA BIDEA</td>\n",
       "      <td>01240</td>\n",
       "      <td>ALEGRIA-DULANTZI</td>\n",
       "      <td>24&lt;&gt;KALE AÑUA BIDEA&lt;&gt;01240&lt;&gt;ALEGRIA-DULANTZI</td>\n",
       "      <td>num rue cp ville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>KALE</td>\n",
       "      <td>GOIKOLANDA</td>\n",
       "      <td>01240</td>\n",
       "      <td>ALEGRIA-DULANTZI</td>\n",
       "      <td>10&lt;&gt;KALE GOIKOLANDA&lt;&gt;01240&lt;&gt;ALEGRIA-DULANTZI</td>\n",
       "      <td>num rue cp ville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>KALE</td>\n",
       "      <td>TORREALDEA</td>\n",
       "      <td>01240</td>\n",
       "      <td>ALEGRIA-DULANTZI</td>\n",
       "      <td>5&lt;&gt;KALE TORREALDEA&lt;&gt;01240&lt;&gt;ALEGRIA-DULANTZI</td>\n",
       "      <td>num rue cp ville</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fin num type de voie nom de voie code postal entité singulière  \\\n",
       "0      27         KALE   TORRONDOA       01240  ALEGRIA-DULANTZI   \n",
       "1      39         KALE  AÑUA BIDEA       01240  ALEGRIA-DULANTZI   \n",
       "2      24         KALE  AÑUA BIDEA       01240  ALEGRIA-DULANTZI   \n",
       "3      10         KALE  GOIKOLANDA       01240  ALEGRIA-DULANTZI   \n",
       "4       5         KALE  TORREALDEA       01240  ALEGRIA-DULANTZI   \n",
       "\n",
       "                                       adresses            labels  \n",
       "0   27<>KALE TORRONDOA<>01240<>ALEGRIA-DULANTZI  num rue cp ville  \n",
       "1  39<>KALE AÑUA BIDEA<>01240<>ALEGRIA-DULANTZI  num rue cp ville  \n",
       "2  24<>KALE AÑUA BIDEA<>01240<>ALEGRIA-DULANTZI  num rue cp ville  \n",
       "3  10<>KALE GOIKOLANDA<>01240<>ALEGRIA-DULANTZI  num rue cp ville  \n",
       "4   5<>KALE TORREALDEA<>01240<>ALEGRIA-DULANTZI  num rue cp ville  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adr_m_vias[[\"fin num\", \"type de voie\", \"nom de voie\", \n",
    "            \"code postal\", \"entité singulière\", \"adresses\", \"labels\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c60f6eb",
   "metadata": {},
   "source": [
    "### sélection corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c1f0295",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_size = len(adr_m_vias)\n",
    "corpus_adr = adr_m_vias[\"adresses\"][:corpus_size].copy()\n",
    "corpus_lab = adr_m_vias[\"labels\"][:corpus_size].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e438ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     27<>KALE TORRONDOA<>01240<>ALEGRIA-DULANTZI\n",
       "1    39<>KALE AÑUA BIDEA<>01240<>ALEGRIA-DULANTZI\n",
       "2    24<>KALE AÑUA BIDEA<>01240<>ALEGRIA-DULANTZI\n",
       "3    10<>KALE GOIKOLANDA<>01240<>ALEGRIA-DULANTZI\n",
       "4     5<>KALE TORREALDEA<>01240<>ALEGRIA-DULANTZI\n",
       "Name: adresses, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_adr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62c5a912",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    num rue cp ville\n",
       "1    num rue cp ville\n",
       "2    num rue cp ville\n",
       "3    num rue cp ville\n",
       "4    num rue cp ville\n",
       "Name: labels, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_lab.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68c53c5",
   "metadata": {},
   "source": [
    "### ajout variabilité dans les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "faf30f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t(x):\n",
    "    # inversion du numéro de rue et du nom de rue\n",
    "    x=x.split(\"<>\")\n",
    "    num, rue = x[0], x[1]\n",
    "    x[0], x[1] = rue, num\n",
    "    return \"<>\".join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "27c6840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tl(x):\n",
    "    # inversion des labels \"num\" et \"rue\"\n",
    "    x=x.split()\n",
    "    num, rue = x[0], x[1]\n",
    "    x[0], x[1] = rue, num\n",
    "    return \" \".join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5dea9a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# application de la transformation à 10% des données\n",
    "freq = int(len(corpus_adr)*0.1)\n",
    "corpus_adr[:freq] = corpus_adr[:freq].transform(t)\n",
    "corpus_lab[:freq] = corpus_lab[:freq].transform(tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "418a2342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mélange des données\n",
    "corpus = pd.DataFrame({\"adresses\":corpus_adr, \"labels\":corpus_lab})\n",
    "corpus = corpus.sample(frac=1)\n",
    "corpus_adr = corpus[\"adresses\"]\n",
    "corpus_lab = corpus[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a53558a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t2(x):\n",
    "    # inversion du code postal et du nom de ville\n",
    "    x=x.split(\"<>\")\n",
    "    cp, ville = x[-2], x[-1]\n",
    "    x[-2], x[-1] = ville, cp\n",
    "    return \"<>\".join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "53a806eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tl2(x):\n",
    "    # inversion des labels \"cp\" et \"ville\"\n",
    "    x=x.split()\n",
    "    cp, ville = x[-2], x[-1]\n",
    "    x[-2], x[-1] = ville, cp\n",
    "    return \" \".join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "92a4f4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# application de la transformation à 30% des données\n",
    "freq = int(len(corpus_adr)*0.3)\n",
    "corpus_adr[:freq] = corpus_adr[:freq].transform(t2)\n",
    "corpus_lab[:freq] = corpus_lab[:freq].transform(tl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1b50db04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mélange des données\n",
    "corpus = pd.DataFrame({\"adresses\":corpus_adr, \"labels\":corpus_lab})\n",
    "corpus = corpus.sample(frac=1)\n",
    "corpus_adr = corpus[\"adresses\"]\n",
    "corpus_lab = corpus[\"labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043b2681",
   "metadata": {},
   "source": [
    "# Statistical modeling - CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2ec060",
   "metadata": {},
   "source": [
    "Conditional random fields are a type of statiscal model designed to deal with sequential data. They evaluate the transition probability between the sequence elements and their categories. This makes them appropriate for the task of adress parsing where we want to categorize correctly each token of an adress. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4b4100",
   "metadata": {},
   "source": [
    "## Naive approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d4a666",
   "metadata": {},
   "source": [
    "### extraction features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "8194a53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract features for each token in an adress\n",
    "def token_features(adress, i):\n",
    "    token = adress[i]\n",
    "    features = {\n",
    "        'token': token,\n",
    "#         'is_first': i == 0, #if the token is the first token\n",
    "#         'is_last': i == len(adress) - 1, #if the token is the last token\n",
    "        'token_length': len(token),\n",
    "#         #prefix of the token\n",
    "#         'prefix-1': token[0], \n",
    "#         'prefix-2': token[:2],\n",
    "#         'prefix-3': token[:3],\n",
    "#         #suffix of the token\n",
    "#         'suffix-1': token[-1],\n",
    "#         'suffix-2': token[-2:],\n",
    "#         'suffix-3': token[-3:],\n",
    "        #extracting previous token\n",
    "        'prev_token': '' if i == 0 else adress[i-1],\n",
    "        #extracting next token\n",
    "        'next_token': '' if i == len(adress)-1 else adress[i+1],\n",
    "        'has_hyphen': '-' in token, #if token has hypen\n",
    "        'is_numeric': token.isdigit(), #if token is in numeric\n",
    "    }\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "c5643f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_adress(adress, labels):\n",
    "    X_adress = []\n",
    "    y_adress = []\n",
    "    labels = labels.split()\n",
    "    elts = adress.split(\"<>\")\n",
    "    k=0\n",
    "    for i, elt in enumerate(elts):\n",
    "        tokens = elt.split()\n",
    "        for j, t in enumerate(tokens):\n",
    "            X_adress.append(token_features(adress.replace(\"<>\", \" \").split(), k))\n",
    "            y_adress.append(labels[i])\n",
    "            k+=1\n",
    "    return X_adress, y_adress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "241d13cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 1440190/1440190 [00:52<00:00, 27389.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# Extract features for each sentence in the corpus\n",
    "X = []\n",
    "y = []\n",
    "for i in tqdm(corpus.index):\n",
    "    X_adress, y_adress = process_adress(corpus_adr[i], corpus_lab[i])\n",
    "    X.append(X_adress)\n",
    "    y.append(y_adress)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "split = int(0.8 * len(X))\n",
    "X_train = X[:split]\n",
    "y_train = y[:split]\n",
    "X_test = X[split:]\n",
    "y_test = y[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796e1041",
   "metadata": {},
   "source": [
    "### entraînement / évaluation modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "7289ea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "ff954f2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|██████████████████████████████████| 1152152/1152152 [01:09<00:00, 16476.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 517163\n",
      "Seconds required: 13.122\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.100000\n",
      "c2: 0.100000\n",
      "num_memories: 6\n",
      "max_iterations: 100\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=13.33 loss=10244522.85 active=509848 feature_norm=0.50\n",
      "Iter 2   time=4.57  loss=9184981.91 active=503081 feature_norm=0.42\n",
      "Iter 3   time=4.46  loss=8946855.00 active=510060 feature_norm=0.39\n",
      "Iter 4   time=4.45  loss=8639884.50 active=504384 feature_norm=0.40\n",
      "Iter 5   time=4.47  loss=8056028.58 active=510033 feature_norm=0.58\n",
      "Iter 6   time=4.47  loss=2541816.05 active=512451 feature_norm=4.73\n",
      "Iter 7   time=4.94  loss=2011539.62 active=501597 feature_norm=5.74\n",
      "Iter 8   time=4.99  loss=1661149.47 active=507309 feature_norm=7.44\n",
      "Iter 9   time=4.97  loss=1427203.36 active=511185 feature_norm=8.60\n",
      "Iter 10  time=5.00  loss=1331697.99 active=513809 feature_norm=9.31\n",
      "Iter 11  time=4.80  loss=1212274.03 active=512991 feature_norm=10.68\n",
      "Iter 12  time=4.90  loss=1144313.54 active=513347 feature_norm=11.31\n",
      "Iter 13  time=4.85  loss=997888.15 active=508956 feature_norm=13.81\n",
      "Iter 14  time=5.16  loss=916024.30 active=506006 feature_norm=16.74\n",
      "Iter 15  time=5.12  loss=869093.77 active=503647 feature_norm=20.99\n",
      "Iter 16  time=4.65  loss=823345.95 active=502822 feature_norm=22.56\n",
      "Iter 17  time=4.89  loss=784628.61 active=495648 feature_norm=25.97\n",
      "Iter 18  time=5.27  loss=746320.67 active=487583 feature_norm=31.10\n",
      "Iter 19  time=5.19  loss=708332.19 active=484085 feature_norm=34.74\n",
      "Iter 20  time=4.77  loss=677643.10 active=476980 feature_norm=36.87\n",
      "Iter 21  time=4.51  loss=643073.89 active=447816 feature_norm=39.78\n",
      "Iter 22  time=4.40  loss=611845.98 active=421886 feature_norm=42.13\n",
      "Iter 23  time=4.41  loss=582148.87 active=411918 feature_norm=45.01\n",
      "Iter 24  time=4.47  loss=554344.54 active=399333 feature_norm=48.12\n",
      "Iter 25  time=5.53  loss=522308.53 active=393822 feature_norm=52.91\n",
      "Iter 26  time=4.59  loss=491769.61 active=387168 feature_norm=59.63\n",
      "Iter 27  time=4.41  loss=460849.15 active=379352 feature_norm=64.54\n",
      "Iter 28  time=4.39  loss=426396.97 active=352751 feature_norm=71.30\n",
      "Iter 29  time=4.41  loss=392746.19 active=338841 feature_norm=79.99\n",
      "Iter 30  time=4.44  loss=361914.19 active=337845 feature_norm=89.48\n",
      "Iter 31  time=4.44  loss=335843.92 active=337048 feature_norm=99.29\n",
      "Iter 32  time=4.45  loss=312340.02 active=336805 feature_norm=110.01\n",
      "Iter 33  time=4.48  loss=287166.42 active=336525 feature_norm=121.27\n",
      "Iter 34  time=4.71  loss=260982.58 active=335536 feature_norm=138.23\n",
      "Iter 35  time=4.72  loss=238037.17 active=335061 feature_norm=152.54\n",
      "Iter 36  time=4.90  loss=220806.90 active=324735 feature_norm=169.66\n",
      "Iter 37  time=31.70 loss=220404.03 active=325552 feature_norm=169.92\n",
      "Iter 38  time=4.49  loss=209474.08 active=313380 feature_norm=177.83\n",
      "Iter 39  time=4.42  loss=193957.69 active=293067 feature_norm=197.41\n",
      "Iter 40  time=4.47  loss=181879.53 active=283713 feature_norm=211.45\n",
      "Iter 41  time=4.50  loss=171456.94 active=268068 feature_norm=223.91\n",
      "Iter 42  time=4.45  loss=158854.30 active=250648 feature_norm=243.86\n",
      "Iter 43  time=4.43  loss=148881.96 active=238259 feature_norm=258.63\n",
      "Iter 44  time=4.42  loss=140134.12 active=231410 feature_norm=271.08\n",
      "Iter 45  time=4.47  loss=131948.61 active=228035 feature_norm=286.07\n",
      "Iter 46  time=4.41  loss=125213.79 active=225715 feature_norm=296.10\n",
      "Iter 47  time=4.44  loss=118979.69 active=219838 feature_norm=308.86\n",
      "Iter 48  time=4.58  loss=113319.90 active=218153 feature_norm=320.29\n",
      "Iter 49  time=4.80  loss=109107.00 active=211341 feature_norm=330.93\n",
      "Iter 50  time=4.81  loss=105646.39 active=202338 feature_norm=340.01\n",
      "Iter 51  time=4.84  loss=102324.17 active=200727 feature_norm=350.25\n",
      "Iter 52  time=4.75  loss=99643.90 active=193246 feature_norm=356.55\n",
      "Iter 53  time=4.93  loss=97004.00 active=186848 feature_norm=365.17\n",
      "Iter 54  time=4.40  loss=95245.38 active=185178 feature_norm=367.91\n",
      "Iter 55  time=4.41  loss=93332.24 active=182601 feature_norm=372.78\n",
      "Iter 56  time=4.42  loss=91439.39 active=175468 feature_norm=377.74\n",
      "Iter 57  time=4.37  loss=89700.79 active=171179 feature_norm=380.65\n",
      "Iter 58  time=4.44  loss=88021.99 active=168982 feature_norm=385.46\n",
      "Iter 59  time=8.87  loss=87392.97 active=166543 feature_norm=380.25\n",
      "Iter 60  time=4.42  loss=86428.81 active=163730 feature_norm=383.14\n",
      "Iter 61  time=4.49  loss=85471.24 active=161152 feature_norm=385.44\n",
      "Iter 62  time=4.52  loss=83842.60 active=157344 feature_norm=387.24\n",
      "Iter 63  time=4.63  loss=82735.41 active=157086 feature_norm=391.10\n",
      "Iter 64  time=5.08  loss=81731.14 active=155862 feature_norm=392.53\n",
      "Iter 65  time=4.51  loss=80324.39 active=152190 feature_norm=394.06\n",
      "Iter 66  time=4.49  loss=79424.28 active=150064 feature_norm=395.72\n",
      "Iter 67  time=4.40  loss=78386.82 active=149251 feature_norm=396.14\n",
      "Iter 68  time=4.52  loss=77282.65 active=147033 feature_norm=397.23\n",
      "Iter 69  time=4.63  loss=76754.50 active=145375 feature_norm=394.06\n",
      "Iter 70  time=4.88  loss=76014.57 active=145211 feature_norm=395.45\n",
      "Iter 71  time=4.41  loss=75502.43 active=144595 feature_norm=395.77\n",
      "Iter 72  time=4.45  loss=74661.69 active=143102 feature_norm=396.17\n",
      "Iter 73  time=4.45  loss=74321.87 active=142584 feature_norm=398.48\n",
      "Iter 74  time=4.39  loss=73719.75 active=142566 feature_norm=398.29\n",
      "Iter 75  time=4.36  loss=73309.86 active=141495 feature_norm=398.76\n",
      "Iter 76  time=4.39  loss=72829.90 active=139377 feature_norm=400.37\n",
      "Iter 77  time=4.41  loss=72525.77 active=138305 feature_norm=401.23\n",
      "Iter 78  time=4.38  loss=72098.05 active=137971 feature_norm=402.39\n",
      "Iter 79  time=4.45  loss=71767.30 active=137617 feature_norm=402.81\n",
      "Iter 80  time=4.89  loss=71321.02 active=135963 feature_norm=403.77\n",
      "Iter 81  time=9.34  loss=71125.83 active=136021 feature_norm=404.05\n",
      "Iter 82  time=4.62  loss=70868.83 active=135638 feature_norm=404.61\n",
      "Iter 83  time=4.82  loss=70548.06 active=135009 feature_norm=404.96\n",
      "Iter 84  time=4.39  loss=70230.58 active=134216 feature_norm=405.20\n",
      "Iter 85  time=4.48  loss=69956.21 active=133571 feature_norm=405.31\n",
      "Iter 86  time=4.59  loss=69721.34 active=133022 feature_norm=405.64\n",
      "Iter 87  time=4.48  loss=69509.17 active=131003 feature_norm=405.78\n",
      "Iter 88  time=4.52  loss=69302.39 active=130367 feature_norm=406.16\n",
      "Iter 89  time=4.54  loss=69089.02 active=129509 feature_norm=406.46\n",
      "Iter 90  time=4.45  loss=68910.48 active=128769 feature_norm=406.75\n",
      "Iter 91  time=4.76  loss=68733.38 active=128089 feature_norm=406.89\n",
      "Iter 92  time=4.93  loss=68575.33 active=127677 feature_norm=407.16\n",
      "Iter 93  time=4.44  loss=68429.55 active=126810 feature_norm=407.30\n",
      "Iter 94  time=4.46  loss=68306.55 active=126438 feature_norm=407.58\n",
      "Iter 95  time=4.44  loss=68180.10 active=126050 feature_norm=407.59\n",
      "Iter 96  time=4.51  loss=68050.59 active=125242 feature_norm=407.78\n",
      "Iter 97  time=4.43  loss=67937.91 active=124335 feature_norm=407.84\n",
      "Iter 98  time=4.50  loss=67825.75 active=123999 feature_norm=408.04\n",
      "Iter 99  time=4.98  loss=67723.08 active=123708 feature_norm=408.13\n",
      "Iter 100 time=4.56  loss=67632.43 active=123265 feature_norm=408.28\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 505.773\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 123265 (517163)\n",
      "Number of active attributes: 81440 (392098)\n",
      "Number of active labels: 4 (4)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.303\n",
      "\n",
      "0.9966955423949748\n"
     ]
    }
   ],
   "source": [
    "# Train a CRF model on the training data\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True,\n",
    "    verbose=True\n",
    ")\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data and evaluate the performance\n",
    "y_pred = crf.predict(X_test)\n",
    "\n",
    "print(metrics.flat_accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6ccbce",
   "metadata": {},
   "source": [
    "### predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "1c2f5add",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "def predict(adress):\n",
    "    print(adress)\n",
    "    X_adress = []\n",
    "    tokens = adress.split()\n",
    "    for i in range(len(tokens)):\n",
    "        X_adress.append(token_features(tokens, i))\n",
    "    tags = crf.predict([X_adress]).tolist()[0]\n",
    "    pprint(list(zip(tokens, tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "91fb262f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 CALLE LA FUENTE (BA) 42318 BARCEBAL\n",
      "[('21', 'num'),\n",
      " ('CALLE', 'rue'),\n",
      " ('LA', 'rue'),\n",
      " ('FUENTE', 'rue'),\n",
      " ('(BA)', 'rue'),\n",
      " ('42318', 'cp'),\n",
      " ('BARCEBAL', 'ville')]\n"
     ]
    }
   ],
   "source": [
    "predict(corpus_adr.iloc[-537].replace(\"<>\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71206593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test[-537]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f602ca9e",
   "metadata": {},
   "source": [
    "## NER-like approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "e74ceead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(i, j, tokens, labels):\n",
    "    if len(tokens)==1:\n",
    "        return \"U-\"+labels[i]\n",
    "    else:\n",
    "        if j==0:\n",
    "            return \"B-\"+labels[i]\n",
    "        elif j==(len(tokens)-1):\n",
    "            return \"L-\"+labels[i]\n",
    "        else:\n",
    "            return \"I-\"+labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "12a41ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_adress_ner(adress, labels):\n",
    "    X_adress = []\n",
    "    y_adress = []\n",
    "    labels = labels.split()\n",
    "    elts = adress.split(\"<>\")\n",
    "    k=0\n",
    "    for i, elt in enumerate(elts):\n",
    "        tokens = elt.split()\n",
    "        for j, t in enumerate(tokens):\n",
    "            X_adress.append(token_features(adress.replace(\"<>\", \" \").split(), k))\n",
    "            y_adress.append(get_label(i, j, tokens, labels))\n",
    "            k+=1\n",
    "    return X_adress, y_adress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "fce182d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 1440190/1440190 [00:55<00:00, 25931.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# Extract features for each sentence in the corpus\n",
    "X = []\n",
    "y = []\n",
    "for i in tqdm(corpus.index):\n",
    "    X_adress, y_adress = process_adress_ner(corpus_adr[i], corpus_lab[i])\n",
    "    X.append(X_adress)\n",
    "    y.append(y_adress)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "split = int(0.8 * len(X))\n",
    "X_train = X[:split]\n",
    "y_train = y[:split]\n",
    "X_test = X[split:]\n",
    "y_test = y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "b405eda0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|██████████████████████████████████| 1152152/1152152 [00:51<00:00, 22252.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 532684\n",
      "Seconds required: 11.471\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.100000\n",
      "c2: 0.100000\n",
      "num_memories: 6\n",
      "max_iterations: 100\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=19.12 loss=9532311.21 active=496574 feature_norm=0.25\n",
      "Iter 2   time=4.55  loss=9259344.86 active=498613 feature_norm=0.27\n",
      "Iter 3   time=4.54  loss=8985506.42 active=472924 feature_norm=0.35\n",
      "Iter 4   time=4.50  loss=7519145.30 active=480973 feature_norm=1.08\n",
      "Iter 5   time=4.45  loss=4710888.87 active=505821 feature_norm=2.83\n",
      "Iter 6   time=4.42  loss=4403321.12 active=498123 feature_norm=4.19\n",
      "Iter 7   time=4.42  loss=3801067.67 active=527615 feature_norm=4.67\n",
      "Iter 8   time=4.47  loss=3583521.73 active=524755 feature_norm=5.27\n",
      "Iter 9   time=4.50  loss=3479718.33 active=516171 feature_norm=6.38\n",
      "Iter 10  time=4.69  loss=3362997.31 active=520239 feature_norm=7.13\n",
      "Iter 11  time=4.48  loss=3297193.60 active=526425 feature_norm=7.72\n",
      "Iter 12  time=4.40  loss=3262319.60 active=526257 feature_norm=8.27\n",
      "Iter 13  time=4.66  loss=3216697.18 active=526765 feature_norm=9.04\n",
      "Iter 14  time=4.67  loss=3180398.36 active=526295 feature_norm=9.76\n",
      "Iter 15  time=4.51  loss=3143534.33 active=525251 feature_norm=10.68\n",
      "Iter 16  time=4.38  loss=3101614.54 active=522438 feature_norm=11.91\n",
      "Iter 17  time=4.45  loss=3027327.19 active=510942 feature_norm=13.85\n",
      "Iter 18  time=8.85  loss=2995975.61 active=516091 feature_norm=14.85\n",
      "Iter 19  time=8.86  loss=2959634.70 active=520837 feature_norm=15.81\n",
      "Iter 20  time=8.82  loss=2924910.53 active=522900 feature_norm=16.77\n",
      "Iter 21  time=4.49  loss=2900158.01 active=504515 feature_norm=19.19\n",
      "Iter 22  time=4.88  loss=2885229.00 active=495200 feature_norm=21.45\n",
      "Iter 23  time=4.66  loss=2820401.55 active=485242 feature_norm=22.59\n",
      "Iter 24  time=4.48  loss=2797649.17 active=487144 feature_norm=23.89\n",
      "Iter 25  time=4.41  loss=2771881.91 active=483789 feature_norm=24.54\n",
      "Iter 26  time=4.48  loss=2751094.40 active=481561 feature_norm=25.35\n",
      "Iter 27  time=4.51  loss=2725322.82 active=482544 feature_norm=26.32\n",
      "Iter 28  time=4.57  loss=2710795.34 active=485611 feature_norm=27.13\n",
      "Iter 29  time=4.44  loss=2699426.63 active=483965 feature_norm=28.20\n",
      "Iter 30  time=4.39  loss=2685700.47 active=485900 feature_norm=28.69\n",
      "Iter 31  time=4.41  loss=2677533.02 active=486125 feature_norm=29.94\n",
      "Iter 32  time=4.43  loss=2665258.56 active=487850 feature_norm=30.65\n",
      "Iter 33  time=4.71  loss=2645646.07 active=478999 feature_norm=32.48\n",
      "Iter 34  time=8.74  loss=2632520.38 active=476873 feature_norm=33.77\n",
      "Iter 35  time=4.49  loss=2618954.81 active=476795 feature_norm=35.53\n",
      "Iter 36  time=4.69  loss=2603914.93 active=479763 feature_norm=36.62\n",
      "Iter 37  time=4.78  loss=2596491.49 active=479831 feature_norm=37.09\n",
      "Iter 38  time=4.78  loss=2561759.24 active=463076 feature_norm=41.84\n",
      "Iter 39  time=4.46  loss=2525906.81 active=466535 feature_norm=43.82\n",
      "Iter 40  time=4.57  loss=2503368.29 active=466285 feature_norm=45.84\n",
      "Iter 41  time=4.54  loss=2475872.02 active=466872 feature_norm=48.56\n",
      "Iter 42  time=4.54  loss=2452427.05 active=467332 feature_norm=50.60\n",
      "Iter 43  time=4.48  loss=2430869.69 active=468936 feature_norm=52.31\n",
      "Iter 44  time=4.49  loss=2399895.48 active=470388 feature_norm=54.16\n",
      "Iter 45  time=4.46  loss=2378236.52 active=469706 feature_norm=57.09\n",
      "Iter 46  time=4.40  loss=2355386.60 active=469866 feature_norm=60.15\n",
      "Iter 47  time=4.51  loss=2331582.33 active=470780 feature_norm=62.22\n",
      "Iter 48  time=4.57  loss=2302000.11 active=470251 feature_norm=66.42\n",
      "Iter 49  time=4.74  loss=2266350.33 active=467962 feature_norm=75.60\n",
      "Iter 50  time=9.24  loss=2240889.89 active=469241 feature_norm=82.25\n",
      "Iter 51  time=4.40  loss=2224656.34 active=468650 feature_norm=92.78\n",
      "Iter 52  time=4.57  loss=2193627.46 active=469465 feature_norm=101.54\n",
      "Iter 53  time=4.76  loss=2181079.36 active=469427 feature_norm=109.56\n",
      "Iter 54  time=4.65  loss=2159926.00 active=469643 feature_norm=118.29\n",
      "Iter 55  time=4.48  loss=2148866.14 active=468681 feature_norm=127.18\n",
      "Iter 56  time=4.48  loss=2128504.88 active=466932 feature_norm=137.10\n",
      "Iter 57  time=4.45  loss=2115341.10 active=466704 feature_norm=144.96\n",
      "Iter 58  time=4.42  loss=2100840.52 active=467373 feature_norm=153.39\n",
      "Iter 59  time=4.53  loss=2088969.52 active=467718 feature_norm=161.09\n",
      "Iter 60  time=4.53  loss=2076978.03 active=466982 feature_norm=168.83\n",
      "Iter 61  time=4.53  loss=2064297.07 active=467468 feature_norm=176.70\n",
      "Iter 62  time=4.50  loss=2056235.92 active=467197 feature_norm=185.29\n",
      "Iter 63  time=4.48  loss=2043361.29 active=467630 feature_norm=193.53\n",
      "Iter 64  time=4.40  loss=2036575.18 active=466333 feature_norm=201.48\n",
      "Iter 65  time=4.43  loss=2027108.37 active=467653 feature_norm=209.93\n",
      "Iter 66  time=4.50  loss=2018831.87 active=467643 feature_norm=218.06\n",
      "Iter 67  time=4.43  loss=2011907.99 active=467454 feature_norm=227.15\n",
      "Iter 68  time=4.41  loss=2003402.75 active=467424 feature_norm=234.92\n",
      "Iter 69  time=4.44  loss=1998693.76 active=466076 feature_norm=243.25\n",
      "Iter 70  time=4.39  loss=1990750.97 active=467660 feature_norm=250.78\n",
      "Iter 71  time=4.71  loss=1984702.50 active=467093 feature_norm=259.12\n",
      "Iter 72  time=4.45  loss=1977982.99 active=464640 feature_norm=268.38\n",
      "Iter 73  time=4.48  loss=1970279.72 active=465867 feature_norm=279.68\n",
      "Iter 74  time=4.50  loss=1961652.95 active=465794 feature_norm=291.72\n",
      "Iter 75  time=4.66  loss=1951656.23 active=465126 feature_norm=308.34\n",
      "Iter 76  time=4.47  loss=1942927.50 active=465102 feature_norm=323.71\n",
      "Iter 77  time=4.49  loss=1935267.85 active=465168 feature_norm=336.63\n",
      "Iter 78  time=4.49  loss=1925948.60 active=460740 feature_norm=359.29\n",
      "Iter 79  time=4.48  loss=1919655.62 active=458103 feature_norm=375.86\n",
      "Iter 80  time=4.45  loss=1912657.21 active=454937 feature_norm=394.59\n",
      "Iter 81  time=4.52  loss=1906971.99 active=456394 feature_norm=405.87\n",
      "Iter 82  time=4.44  loss=1900358.23 active=455235 feature_norm=419.46\n",
      "Iter 83  time=4.45  loss=1894570.61 active=455807 feature_norm=424.89\n",
      "Iter 84  time=4.76  loss=1888937.65 active=451373 feature_norm=430.86\n",
      "Iter 85  time=4.73  loss=1883243.59 active=452360 feature_norm=432.15\n",
      "Iter 86  time=4.91  loss=1877767.34 active=449449 feature_norm=434.44\n",
      "Iter 87  time=4.45  loss=1872344.46 active=449984 feature_norm=438.15\n",
      "Iter 88  time=22.26 loss=1871206.07 active=451310 feature_norm=443.00\n",
      "Iter 89  time=4.47  loss=1866081.50 active=448457 feature_norm=447.35\n",
      "Iter 90  time=4.45  loss=1861884.07 active=447341 feature_norm=452.27\n",
      "Iter 91  time=4.43  loss=1857610.02 active=443630 feature_norm=458.01\n",
      "Iter 92  time=4.45  loss=1855640.44 active=444546 feature_norm=462.48\n",
      "Iter 93  time=4.49  loss=1851794.05 active=446631 feature_norm=463.96\n",
      "Iter 94  time=4.61  loss=1849434.10 active=445086 feature_norm=466.50\n",
      "Iter 95  time=4.44  loss=1844619.67 active=441903 feature_norm=473.08\n",
      "Iter 96  time=8.91  loss=1843939.33 active=440598 feature_norm=477.87\n",
      "Iter 97  time=4.51  loss=1840572.92 active=443669 feature_norm=480.58\n",
      "Iter 98  time=4.49  loss=1838677.77 active=443752 feature_norm=482.71\n",
      "Iter 99  time=4.45  loss=1835736.73 active=442150 feature_norm=487.95\n",
      "Iter 100 time=4.51  loss=1833387.79 active=441987 feature_norm=490.66\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 510.776\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 441987 (532684)\n",
      "Number of active attributes: 198135 (258449)\n",
      "Number of active labels: 4 (4)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.887\n",
      "\n",
      "0.8644135352037898\n"
     ]
    }
   ],
   "source": [
    "# Train a CRF model on the training data\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True,\n",
    "    verbose=True\n",
    ")\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data and evaluate the performance\n",
    "y_pred = crf.predict(X_test)\n",
    "\n",
    "print(metrics.flat_accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3af5ac",
   "metadata": {},
   "source": [
    "## Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2d38bd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "41217948",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichiers dans l'archive ZIP :\n",
      "['LIST', 'meta.json', 'model.bin', 'model.txt', 'README']\n",
      "\n",
      "Contenu du fichier LIST :\n",
      "b'es-common_crawl-257\\n'\n",
      "b'es-common_crawl-328\\n'\n",
      "b'es-common_crawl-119\\n'\n",
      "b'es-common_crawl-199\\n'\n",
      "b'es-common_crawl-172\\n'\n",
      "b'es-common_crawl-141\\n'\n",
      "b'es-common_crawl-017\\n'\n",
      "b'es-common_crawl-296\\n'\n",
      "b'es-common_crawl-330\\n'\n",
      "b'es-common_crawl-350\\n'\n",
      "b'es-common_crawl-046\\n'\n",
      "b'es-common_crawl-189\\n'\n",
      "b'es-common_crawl-077\\n'\n",
      "b'es-common_crawl-059\\n'\n",
      "b'es-common_crawl-102\\n'\n",
      "b'es-common_crawl-084\\n'\n",
      "b'es-common_crawl-283\\n'\n",
      "b'es-common_crawl-204\\n'\n",
      "b'es-wikipedia-013\\n'\n",
      "b'es-common_crawl-312\\n'\n",
      "b'es-common_crawl-343\\n'\n",
      "b'es-common_crawl-074\\n'\n",
      "b'es-common_crawl-249\\n'\n",
      "b'es-common_crawl-342\\n'\n",
      "b'es-common_crawl-377\\n'\n",
      "b'es-common_crawl-033\\n'\n",
      "b'es-common_crawl-022\\n'\n",
      "b'es-common_crawl-006\\n'\n",
      "b'es-common_crawl-365\\n'\n",
      "b'es-common_crawl-062\\n'\n",
      "b'es-common_crawl-336\\n'\n",
      "b'es-common_crawl-166\\n'\n",
      "b'es-common_crawl-021\\n'\n",
      "b'es-common_crawl-383\\n'\n",
      "b'es-wikipedia-015\\n'\n",
      "b'es-wikipedia-017\\n'\n",
      "b'es-common_crawl-313\\n'\n",
      "b'es-common_crawl-231\\n'\n",
      "b'es-common_crawl-224\\n'\n",
      "b'es-common_crawl-247\\n'\n",
      "b'es-common_crawl-103\\n'\n",
      "b'es-common_crawl-223\\n'\n",
      "b'es-common_crawl-090\\n'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[137], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m#                 print(fichier.read().decode('utf-8'))  # Décodage en fonction du type de fichier\u001b[39;00m\n\u001b[0;32m     35\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m fichier:\n\u001b[1;32m---> 36\u001b[0m                     \u001b[38;5;28mprint\u001b[39m(line); sleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mErreur \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m lors de la récupération du fichier ZIP\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "# URL du fichier ZIP en ligne\n",
    "url = 'http://vectors.nlpl.eu/repository/20/68.zip' # lowercased\n",
    "\n",
    "# Faire une requête GET en mode streaming\n",
    "response = requests.get(url, stream=True)\n",
    "\n",
    "# Vérifier que la requête a réussi\n",
    "if response.status_code == 200:\n",
    "    # Utiliser un objet BytesIO pour charger le contenu du fichier ZIP dans un flux en mémoire\n",
    "    fichier_zip = io.BytesIO()\n",
    "\n",
    "    # Lire et écrire les chunks dans le flux en mémoire\n",
    "    for chunk in response.iter_content(chunk_size=1024):\n",
    "        fichier_zip.write(chunk)\n",
    "\n",
    "    # Remettre le pointeur du flux en début\n",
    "    fichier_zip.seek(0)\n",
    "else:\n",
    "    print(f\"Erreur {response.status_code} lors de la récupération du fichier ZIP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b62cdb69",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"algorithm\": {\n",
      "        \"command\": \"word2vec -min-count 10 -size 100 -window 10 -negative 5 -iter 2 -threads 16 -cbow 0 -binary 0\",\n",
      "        \"id\": 3,\n",
      "        \"name\": \"Word2Vec Continuous Skipgram\",\n",
      "        \"tool\": \"word2vec\",\n",
      "        \"url\": \"https://code.google.com/archive/p/word2vec/\",\n",
      "        \"version\": null\n",
      "    },\n",
      "    \"contents\": [\n",
      "        {\n",
      "            \"filename\": \"model.txt\",\n",
      "            \"format\": \"text\"\n",
      "        },\n",
      "        {\n",
      "            \"filename\": \"meta.json\",\n",
      "            \"format\": \"json\"\n",
      "        },\n",
      "        {\n",
      "            \"filename\": \"LIST\",\n",
      "            \"format\": \"text\"\n",
      "        }\n",
      "    ],\n",
      "    \"corpus\": [\n",
      "        {\n",
      "            \"NER\": false,\n",
      "            \"case preserved\": false,\n",
      "            \"description\": \"Spanish CoNLL17 corpus\",\n",
      "            \"id\": 68,\n",
      "            \"language\": \"spa\",\n",
      "            \"lemmatized\": false,\n",
      "            \"public\": true,\n",
      "            \"stop words removal\": null,\n",
      "            \"tagger\": null,\n",
      "            \"tagset\": null,\n",
      "            \"tokens\": 5967877096,\n",
      "            \"tool\": null,\n",
      "            \"url\": null\n",
      "        }\n",
      "    ],\n",
      "    \"creators\": [\n",
      "        {\n",
      "            \"email\": \"andreku@ifi.uio.no\",\n",
      "            \"name\": \"Andrey Kutuzov\"\n",
      "        }\n",
      "    ],\n",
      "    \"dimensions\": 100,\n",
      "    \"handle\": \"http://vectors.nlpl.eu/repository/20/68.zip\",\n",
      "    \"id\": 68,\n",
      "    \"iterations\": 2,\n",
      "    \"vocabulary size\": 2656057,\n",
      "    \"window\": 10\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Embeddings metadata\n",
    "with zipfile.ZipFile(fichier_zip, 'r') as archive_zip:\n",
    "    with archive_zip.open(\"meta.json\") as fichier:\n",
    "        print(fichier.read().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "aac66e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d43cef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4904d704",
   "metadata": {},
   "outputs": [],
   "source": [
    "errs=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "2797b131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichiers dans l'archive ZIP :\n",
      "['LIST', 'meta.json', 'model.bin', 'model.txt', 'README']\n",
      "\n",
      "Contenu du fichier model.txt :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2656057it [02:54, 15254.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# Ouvrir le fichier ZIP directement depuis le flux en mémoire\n",
    "with zipfile.ZipFile(fichier_zip, 'r') as archive_zip:\n",
    "    # Lister les fichiers dans l'archive ZIP\n",
    "    print(\"Fichiers dans l'archive ZIP :\")\n",
    "    print(archive_zip.namelist())\n",
    "\n",
    "    # Extraire et lire chaque fichier dans l'archive sans tout charger en mémoire\n",
    "    for file_name in archive_zip.namelist():\n",
    "        with archive_zip.open(file_name) as fichier:\n",
    "            if file_name==\"model.txt\":\n",
    "                # Lire et afficher le contenu de chaque fichier dans l'archive\n",
    "                print(f\"\\nContenu du fichier {file_name} :\")\n",
    "                fichier.readline()\n",
    "                for line in tqdm(fichier):\n",
    "                    try:\n",
    "                        line = line.decode().split()\n",
    "                        embeddings[line[0]] = np.array(line[1:], dtype=float)\n",
    "                    except UnicodeDecodeError:\n",
    "                        errs.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "6f9742af",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "for w in embeddings:\n",
    "    if w.isalpha() and not w.islower():\n",
    "        a.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "8610a28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2656037"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "94f4e42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "a08b32c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lex in nlp.vocab:\n",
    "    vocab.add(lex.text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "9fc4a98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15656"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "66be4632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['benalmadena', '03740', 'vizcaino', '39700', 'vargas']"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vocab)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "3a59cdea",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.074875, -0.298918, -0.039462, -0.405561,  0.140007, -0.793524,\n",
       "       -0.569674,  0.066463,  0.222174,  0.567297,  0.768356, -0.102119,\n",
       "        0.030638, -0.270314,  0.231208,  0.261223,  1.453737,  0.388108,\n",
       "       -0.034544,  0.334545,  0.419761,  0.639755, -0.386967, -0.618236,\n",
       "       -0.207673,  0.163131, -0.091391,  0.117188,  0.748305, -0.600575,\n",
       "       -0.298912, -0.909222, -0.260297,  0.245753, -0.625691,  0.492283,\n",
       "        1.000935,  0.807789,  0.598377, -0.469359,  0.37331 ,  0.266725,\n",
       "       -0.378582,  0.228711,  1.350615,  0.131113,  0.602769,  0.178402,\n",
       "       -0.610236, -0.340824, -0.267198,  0.535875,  0.122946, -0.261453,\n",
       "        0.262169, -0.313327,  0.616017, -0.241744,  0.040091, -0.279985,\n",
       "        0.715574, -0.012725,  0.153394,  0.163833,  0.043303,  0.741668,\n",
       "        0.098392,  0.253791,  0.446562,  0.425529,  0.043278, -0.14111 ,\n",
       "        0.318389, -0.325201,  0.233115, -0.56962 ,  0.242946, -0.405108,\n",
       "       -0.128333,  0.431896,  0.615846,  0.354486, -0.185486, -0.447206,\n",
       "        0.748941,  0.47887 , -0.622434, -0.404748, -0.30804 , -0.205711,\n",
       "       -0.206183,  1.109963,  0.152504, -0.206575,  0.128196, -0.887939,\n",
       "       -0.153776, -0.825289,  0.128771,  0.153171])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[\"benalmadena\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "5ca3ede2",
   "metadata": {},
   "outputs": [],
   "source": [
    "oov=set()\n",
    "for w in vocab:\n",
    "    if w not in embeddings:\n",
    "        oov.add(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "4be06096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2786"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "2449c5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coiñas', 'llavanera', 'puigfarners', 'esfiliana', '17181']"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(oov)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13707cd6",
   "metadata": {},
   "source": [
    "# Deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f73fad2",
   "metadata": {},
   "source": [
    "Le problème de parsing d'adresses postales peut se rapprocher d'un problème de reconnaissance d'entités nommées (NER). Il s'agit de classifier une séquence de tokens en sachant qu'une catégorie d'une adresse postale - le nom de la rue, par exemple - peut s'étendre sur plusieurs tokens. Il en est de même pour les entités nommées. Par exemple un nom de personne s'étendra souvent sur 2 tokens ou plus (nom et prénom).  \n",
    "  \n",
    "Spacy est une libairie performante pour le problème de reconnaissance des entités nommées. C'est une librairie \"high-level\" basée sur des réseaux de neurones. C'est cette solution que j'ai choisi pour la partie deep learning de résolution du usecase. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6126af3a",
   "metadata": {},
   "source": [
    "### Librairie Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3489c761",
   "metadata": {},
   "source": [
    "L'architecture est composée d'une couche d'embeddings suivie de réseaux convolutifs pour capturer le contexte. L'output sert à prédire la prochaine action à effectuer dans un algorithme de parsing séquentiel de type shift-reduce.  \n",
    "  \n",
    "L'inconvénient de cette librairie est son opacité. Il semble par exemple difficile d'accéder aux vecteurs contextuels des mots. De même, il est difficile d'accéder aux features utilisés à l'étape finale de prédiction. Ceux-ci sont malgré tout présentés dans une vidéo du fondateur de Spacy et sont les suivants:  \n",
    "mot courant, mot précédant, mot suivant; premier et dernier mot de l'entité précédente, dernier mot de l'entité encore avant  \n",
    "Il n'est pas clair si ces features sont personnalisables ou non, même si cela semble probable étant donné que cette flexibilité est mise en avant comme un des atouts de leur solution.  \n",
    "  \n",
    "Concernant les embeddings, il est possible de charger des embeddings pré-entraînés. De même, il est possible de changer leur architecture à base de CNN par une architecture de type transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb956695",
   "metadata": {},
   "source": [
    "### Comparaison CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25508a84",
   "metadata": {},
   "source": [
    "Les résultats obtenus dans les mêmes conditions qu'avec les CRF plus haut sont largement supérieurs. Là où les CRF atteignent un f1-score de 0.86, le module NER de Spacy atteint un score au-delà de 0.99. Cela peut également laisser supposer un overfitting qui demande à être contrôlé en ajoutant de la variabilité dans les données de développement. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21711247",
   "metadata": {},
   "source": [
    "Le coût computationnel est bien entendu supérieur. Là où le CRF a pu réaliser 100 époques en 10 minutes, le module NER de Spacy a pris plusieurs heures pour réaliser une seule époque. A noter néanmoins la possibilité de basculer une partie des calculs sur le GPU pour améliorer les performances. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bdcf91",
   "metadata": {},
   "source": [
    "### Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22988690",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b0e375a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(raw_adress, raw_labels):\n",
    "    adress_parts = raw_adress.split(\"<>\")\n",
    "    labels = raw_labels.split()\n",
    "    labels_new = {\"entities\":[]}\n",
    "    left_bound = 0\n",
    "    for i, ap in enumerate(adress_parts):\n",
    "        labels_new[\"entities\"].append((left_bound, left_bound+len(ap), labels[i]))\n",
    "        left_bound += len(ap)+1\n",
    "    return (raw_adress.replace(\"<>\", \" \"), labels_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "16dfb618",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 47782.82it/s]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for i in tqdm(range(len(corpus_adr[:10000]))):\n",
    "    data.append(format_data(corpus_adr.iloc[i], corpus_lab.iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "52dac6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(len(data)*0.8)\n",
    "train_data = data[:split]\n",
    "test_data = data[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b488708",
   "metadata": {},
   "source": [
    "### Initialisation modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a4f61df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"es\")\n",
    "\n",
    "ner = nlp.add_pipe(\"ner\")\n",
    "\n",
    "for label in corpus_lab.iloc[0].split():\n",
    "    ner.add_label(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dc97c6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 8000/8000 [00:02<00:00, 2900.12it/s]\n"
     ]
    }
   ],
   "source": [
    "from spacy.training.example import Example\n",
    "\n",
    "for i in tqdm(range(len(train_data))):\n",
    "    text, labels = train_data[i]\n",
    "    doc = nlp.make_doc(text)\n",
    "    train_data[i] = Example.from_dict(doc, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bec987",
   "metadata": {},
   "source": [
    "### Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ab2d6bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:24, 10.05it/s]\n"
     ]
    }
   ],
   "source": [
    "from spacy.util import minibatch\n",
    "\n",
    "optimizer = nlp.begin_training()\n",
    "\n",
    "batches = minibatch(train_data, size=32)\n",
    "for batch in tqdm(batches):\n",
    "    nlp.update(batch, drop=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fe257d",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f86edaa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:00<00:00, 2925.95it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(test_data))):\n",
    "    text, labels = test_data[i]\n",
    "    doc = nlp.make_doc(text)\n",
    "    test_data[i] = Example.from_dict(doc, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "65e80278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_acc': 1.0,\n",
       " 'token_p': 1.0,\n",
       " 'token_r': 1.0,\n",
       " 'token_f': 1.0,\n",
       " 'ents_p': 0.9574328749181401,\n",
       " 'ents_r': 0.91375,\n",
       " 'ents_f': 0.935081547809402,\n",
       " 'ents_per_type': {'num': {'p': 0.998001998001998,\n",
       "   'r': 0.999,\n",
       "   'f': 0.9985007496251873},\n",
       "  'rue': {'p': 0.846382556987116, 'r': 0.854, 'f': 0.8501742160278746},\n",
       "  'cp': {'p': 0.998003992015968, 'r': 1.0, 'f': 0.9990009990009989},\n",
       "  'ville': {'p': 0.9956548727498448, 'r': 0.802, 'f': 0.8883965660481861}},\n",
       " 'speed': 9822.797372583555}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ae4b2df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "12 num\n",
      "CALLE GOYA VEREDA (LA) rue\n",
      "30300 cp\n",
      "\n",
      "0 num\n",
      "RONDA HOSPITAL rue\n",
      "27700 cp\n",
      "RIBADEO ville\n",
      "\n",
      "2 num\n",
      "CRRIL CIPRESES rue\n",
      "30139 cp\n",
      "HUERTA DEL RAAL ville\n",
      "\n",
      "77 num\n",
      "CARRE JOSEP NEBOT rue\n",
      "12540 cp\n",
      "\n",
      "CALLE BELICE-PUEBLO PRINCIPE rue\n",
      "1 num\n",
      "03189 cp\n",
      "ORIHUELA COSTA ville\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    doc = nlp(data[-i][0]); print()\n",
    "\n",
    "    # Parcourir les entités détectées\n",
    "    for ent in doc.ents:\n",
    "        print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "309e8493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp.to_disk(\"spacy_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uc",
   "language": "python",
   "name": "uc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
