{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47181978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f8a631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51592d8b",
   "metadata": {},
   "source": [
    "### Adresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0db84a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_adr_i = [(0,2), (2,5), (13,20),\n",
    "            (110,135), (257,262), (165,190), (160,165),\n",
    "            (262,263), (263,267), (268,272)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65c7c950",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_adr_n = [\"code province\", \"code commune\", \"code unité pop\",\n",
    "            \"entité singulière\", \"code postal\", \"nom abrégé voie\",\"code voie\",\n",
    "            \"type num\", \"début num\", \"fin num\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2af7205",
   "metadata": {},
   "outputs": [],
   "source": [
    "adr_p02 = r\"P02\\TRAM.P02.D240630.G240703\" # P02\n",
    "adr_all = r\"caj_esp_072024\\TRAM.P01-52.D240630.G240703\" #  P01-52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3cd6896",
   "metadata": {},
   "outputs": [],
   "source": [
    "adr = pd.read_fwf(adr_all, colspecs=col_adr_i, header=None, encoding='ISO-8859-1', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0f6be4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adr.columns = col_adr_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a2d796f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code province</th>\n",
       "      <th>code commune</th>\n",
       "      <th>code unité pop</th>\n",
       "      <th>entité singulière</th>\n",
       "      <th>code postal</th>\n",
       "      <th>nom abrégé voie</th>\n",
       "      <th>code voie</th>\n",
       "      <th>type num</th>\n",
       "      <th>début num</th>\n",
       "      <th>fin num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>0001701</td>\n",
       "      <td>ALEGRIA-DULANTZI</td>\n",
       "      <td>01240</td>\n",
       "      <td>TORRONDOA</td>\n",
       "      <td>01001</td>\n",
       "      <td>1</td>\n",
       "      <td>0001</td>\n",
       "      <td>0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>0001701</td>\n",
       "      <td>ALEGRIA-DULANTZI</td>\n",
       "      <td>01240</td>\n",
       "      <td>AÑUA BIDEA</td>\n",
       "      <td>01002</td>\n",
       "      <td>1</td>\n",
       "      <td>0009</td>\n",
       "      <td>0039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>0001701</td>\n",
       "      <td>ALEGRIA-DULANTZI</td>\n",
       "      <td>01240</td>\n",
       "      <td>AÑUA BIDEA</td>\n",
       "      <td>01002</td>\n",
       "      <td>2</td>\n",
       "      <td>0004</td>\n",
       "      <td>0024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>0001701</td>\n",
       "      <td>ALEGRIA-DULANTZI</td>\n",
       "      <td>01240</td>\n",
       "      <td>GOIKOLANDA</td>\n",
       "      <td>01003</td>\n",
       "      <td>2</td>\n",
       "      <td>0002</td>\n",
       "      <td>0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>0001701</td>\n",
       "      <td>ALEGRIA-DULANTZI</td>\n",
       "      <td>01240</td>\n",
       "      <td>TORREALDEA</td>\n",
       "      <td>01004</td>\n",
       "      <td>1</td>\n",
       "      <td>0005</td>\n",
       "      <td>0005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code province code commune code unité pop entité singulière code postal  \\\n",
       "0            01          001        0001701  ALEGRIA-DULANTZI       01240   \n",
       "1            01          001        0001701  ALEGRIA-DULANTZI       01240   \n",
       "2            01          001        0001701  ALEGRIA-DULANTZI       01240   \n",
       "3            01          001        0001701  ALEGRIA-DULANTZI       01240   \n",
       "4            01          001        0001701  ALEGRIA-DULANTZI       01240   \n",
       "\n",
       "  nom abrégé voie code voie type num début num fin num  \n",
       "0       TORRONDOA     01001        1      0001    0027  \n",
       "1      AÑUA BIDEA     01002        1      0009    0039  \n",
       "2      AÑUA BIDEA     01002        2      0004    0024  \n",
       "3      GOIKOLANDA     01003        2      0002    0010  \n",
       "4      TORREALDEA     01004        1      0005    0005  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea875b34",
   "metadata": {},
   "source": [
    "### Noms de voies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20e93c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_vias_i = [(0,2), (2,5), (22,27), (27,32), \n",
    "               (32,33), (33,83), (83,108)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3363edc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_vias_n = [\"code province\", \"code commune\", \"code voie\", \n",
    "               \"type de voie\", \"pos type voie\", \"nom de voie\", \"nom court\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c70ef6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vias_p02 = r\"P02\\VIAS.P02.D240630.G240703\" # P02\n",
    "vias_all = r\"caj_esp_072024\\VIAS.P01-52.D240630.G240703\" # P01-52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac0d6b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vias = pd.read_fwf(vias_all, colspecs=cols_vias_i, header=None, encoding='ISO-8859-1', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d4bc4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vias.columns = cols_vias_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dfb50ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code province</th>\n",
       "      <th>code commune</th>\n",
       "      <th>code voie</th>\n",
       "      <th>type de voie</th>\n",
       "      <th>pos type voie</th>\n",
       "      <th>nom de voie</th>\n",
       "      <th>nom court</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001</td>\n",
       "      <td>KALE</td>\n",
       "      <td>0</td>\n",
       "      <td>TORRONDOA</td>\n",
       "      <td>TORRONDOA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01002</td>\n",
       "      <td>KALE</td>\n",
       "      <td>0</td>\n",
       "      <td>AÑUA BIDEA</td>\n",
       "      <td>AÑUA BIDEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01003</td>\n",
       "      <td>KALE</td>\n",
       "      <td>0</td>\n",
       "      <td>GOIKOLANDA</td>\n",
       "      <td>GOIKOLANDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01004</td>\n",
       "      <td>KALE</td>\n",
       "      <td>0</td>\n",
       "      <td>TORREALDEA</td>\n",
       "      <td>TORREALDEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01005</td>\n",
       "      <td>CALLE</td>\n",
       "      <td>0</td>\n",
       "      <td>NUESTRA SEÑORA DE AIALA</td>\n",
       "      <td>NUESTRA SEÑORA DE AIALA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code province code commune code voie type de voie pos type voie  \\\n",
       "0            01          001     01001         KALE             0   \n",
       "1            01          001     01002         KALE             0   \n",
       "2            01          001     01003         KALE             0   \n",
       "3            01          001     01004         KALE             0   \n",
       "4            01          001     01005        CALLE             0   \n",
       "\n",
       "               nom de voie                nom court  \n",
       "0                TORRONDOA                TORRONDOA  \n",
       "1               AÑUA BIDEA               AÑUA BIDEA  \n",
       "2               GOIKOLANDA               GOIKOLANDA  \n",
       "3               TORREALDEA               TORREALDEA  \n",
       "4  NUESTRA SEÑORA DE AIALA  NUESTRA SEÑORA DE AIALA  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vias.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b873f7",
   "metadata": {},
   "source": [
    "### préparation corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c665165",
   "metadata": {},
   "outputs": [],
   "source": [
    "adr_m_vias = pd.merge(adr, vias, on=[\"code province\", \"code commune\", \"code voie\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd39a658",
   "metadata": {},
   "outputs": [],
   "source": [
    "adr_m_vias[\"fin num\"] = adr_m_vias[\"fin num\"].astype(int)\n",
    "adr_m_vias[\"fin num\"] = adr_m_vias[\"fin num\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bc72f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "adr_m_vias[\"adresses\"] = (adr_m_vias[\"fin num\"]+\"<>\"+\n",
    "                         adr_m_vias[\"type de voie\"]+\" \"+\n",
    "                         adr_m_vias[\"nom de voie\"]+\"<>\"+\n",
    "                         adr_m_vias[\"code postal\"]+\"<>\"+\n",
    "                         adr_m_vias[\"entité singulière\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7035f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "adr_m_vias[\"labels\"] = \"num rue cp ville\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "521e344d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fin num</th>\n",
       "      <th>type de voie</th>\n",
       "      <th>nom de voie</th>\n",
       "      <th>code postal</th>\n",
       "      <th>entité singulière</th>\n",
       "      <th>adresses</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>KALE</td>\n",
       "      <td>TORRONDOA</td>\n",
       "      <td>01240</td>\n",
       "      <td>ALEGRIA-DULANTZI</td>\n",
       "      <td>27&lt;&gt;KALE TORRONDOA&lt;&gt;01240&lt;&gt;ALEGRIA-DULANTZI</td>\n",
       "      <td>num rue cp ville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>KALE</td>\n",
       "      <td>AÑUA BIDEA</td>\n",
       "      <td>01240</td>\n",
       "      <td>ALEGRIA-DULANTZI</td>\n",
       "      <td>39&lt;&gt;KALE AÑUA BIDEA&lt;&gt;01240&lt;&gt;ALEGRIA-DULANTZI</td>\n",
       "      <td>num rue cp ville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>KALE</td>\n",
       "      <td>AÑUA BIDEA</td>\n",
       "      <td>01240</td>\n",
       "      <td>ALEGRIA-DULANTZI</td>\n",
       "      <td>24&lt;&gt;KALE AÑUA BIDEA&lt;&gt;01240&lt;&gt;ALEGRIA-DULANTZI</td>\n",
       "      <td>num rue cp ville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>KALE</td>\n",
       "      <td>GOIKOLANDA</td>\n",
       "      <td>01240</td>\n",
       "      <td>ALEGRIA-DULANTZI</td>\n",
       "      <td>10&lt;&gt;KALE GOIKOLANDA&lt;&gt;01240&lt;&gt;ALEGRIA-DULANTZI</td>\n",
       "      <td>num rue cp ville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>KALE</td>\n",
       "      <td>TORREALDEA</td>\n",
       "      <td>01240</td>\n",
       "      <td>ALEGRIA-DULANTZI</td>\n",
       "      <td>5&lt;&gt;KALE TORREALDEA&lt;&gt;01240&lt;&gt;ALEGRIA-DULANTZI</td>\n",
       "      <td>num rue cp ville</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fin num type de voie nom de voie code postal entité singulière  \\\n",
       "0      27         KALE   TORRONDOA       01240  ALEGRIA-DULANTZI   \n",
       "1      39         KALE  AÑUA BIDEA       01240  ALEGRIA-DULANTZI   \n",
       "2      24         KALE  AÑUA BIDEA       01240  ALEGRIA-DULANTZI   \n",
       "3      10         KALE  GOIKOLANDA       01240  ALEGRIA-DULANTZI   \n",
       "4       5         KALE  TORREALDEA       01240  ALEGRIA-DULANTZI   \n",
       "\n",
       "                                       adresses            labels  \n",
       "0   27<>KALE TORRONDOA<>01240<>ALEGRIA-DULANTZI  num rue cp ville  \n",
       "1  39<>KALE AÑUA BIDEA<>01240<>ALEGRIA-DULANTZI  num rue cp ville  \n",
       "2  24<>KALE AÑUA BIDEA<>01240<>ALEGRIA-DULANTZI  num rue cp ville  \n",
       "3  10<>KALE GOIKOLANDA<>01240<>ALEGRIA-DULANTZI  num rue cp ville  \n",
       "4   5<>KALE TORREALDEA<>01240<>ALEGRIA-DULANTZI  num rue cp ville  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adr_m_vias[[\"fin num\", \"type de voie\", \"nom de voie\", \n",
    "            \"code postal\", \"entité singulière\", \"adresses\", \"labels\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c60f6eb",
   "metadata": {},
   "source": [
    "### sélection corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c1f0295",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_size = len(adr_m_vias)\n",
    "corpus_adr = adr_m_vias[\"adresses\"][:corpus_size].copy()\n",
    "corpus_lab = adr_m_vias[\"labels\"][:corpus_size].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e438ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     27<>KALE TORRONDOA<>01240<>ALEGRIA-DULANTZI\n",
       "1    39<>KALE AÑUA BIDEA<>01240<>ALEGRIA-DULANTZI\n",
       "2    24<>KALE AÑUA BIDEA<>01240<>ALEGRIA-DULANTZI\n",
       "3    10<>KALE GOIKOLANDA<>01240<>ALEGRIA-DULANTZI\n",
       "4     5<>KALE TORREALDEA<>01240<>ALEGRIA-DULANTZI\n",
       "Name: adresses, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_adr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62c5a912",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    num rue cp ville\n",
       "1    num rue cp ville\n",
       "2    num rue cp ville\n",
       "3    num rue cp ville\n",
       "4    num rue cp ville\n",
       "Name: labels, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_lab.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68c53c5",
   "metadata": {},
   "source": [
    "### ajout variabilité dans les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "faf30f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t(x):\n",
    "    # inversion du numéro de rue et du nom de rue\n",
    "    x=x.split(\"<>\")\n",
    "    num, rue = x[0], x[1]\n",
    "    x[0], x[1] = rue, num\n",
    "    return \"<>\".join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27c6840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tl(x):\n",
    "    # inversion des labels \"num\" et \"rue\"\n",
    "    x=x.split()\n",
    "    num, rue = x[0], x[1]\n",
    "    x[0], x[1] = rue, num\n",
    "    return \" \".join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5dea9a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# application de la transformation à 10% des données\n",
    "freq = int(len(corpus_adr)*0.1)\n",
    "corpus_adr[:freq] = corpus_adr[:freq].transform(t)\n",
    "corpus_lab[:freq] = corpus_lab[:freq].transform(tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "418a2342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mélange des données\n",
    "corpus = pd.DataFrame({\"adresses\":corpus_adr, \"labels\":corpus_lab})\n",
    "corpus = corpus.sample(frac=1)\n",
    "corpus_adr = corpus[\"adresses\"]\n",
    "corpus_lab = corpus[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a53558a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t2(x):\n",
    "    # inversion du code postal et du nom de ville\n",
    "    x=x.split(\"<>\")\n",
    "    cp, ville = x[-2], x[-1]\n",
    "    x[-2], x[-1] = ville, cp\n",
    "    return \"<>\".join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53a806eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tl2(x):\n",
    "    # inversion des labels \"cp\" et \"ville\"\n",
    "    x=x.split()\n",
    "    cp, ville = x[-2], x[-1]\n",
    "    x[-2], x[-1] = ville, cp\n",
    "    return \" \".join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92a4f4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# application de la transformation à 30% des données\n",
    "freq = int(len(corpus_adr)*0.3)\n",
    "corpus_adr[:freq] = corpus_adr[:freq].transform(t2)\n",
    "corpus_lab[:freq] = corpus_lab[:freq].transform(tl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b50db04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mélange des données\n",
    "corpus = pd.DataFrame({\"adresses\":corpus_adr, \"labels\":corpus_lab})\n",
    "corpus = corpus.sample(frac=1)\n",
    "corpus_adr = corpus[\"adresses\"]\n",
    "corpus_lab = corpus[\"labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043b2681",
   "metadata": {},
   "source": [
    "# Statistical modeling - CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2ec060",
   "metadata": {},
   "source": [
    "Conditional random fields are a type of statiscal model designed to deal with sequential data. They evaluate the transition probability between the sequence elements and their categories. This makes them appropriate for the task of adress parsing where we want to categorize correctly each token of an adress. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4b4100",
   "metadata": {},
   "source": [
    "## Naive approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d4a666",
   "metadata": {},
   "source": [
    "### extraction features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8194a53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract features for each token in an adress\n",
    "def token_features(adress, i):\n",
    "    token = adress[i]\n",
    "    features = {\n",
    "        'token': token,\n",
    "#         'is_first': i == 0, #if the token is the first token\n",
    "#         'is_last': i == len(adress) - 1, #if the token is the last token\n",
    "        'token_length': len(token),\n",
    "#         #prefix of the token\n",
    "#         'prefix-1': token[0], \n",
    "#         'prefix-2': token[:2],\n",
    "#         'prefix-3': token[:3],\n",
    "#         #suffix of the token\n",
    "#         'suffix-1': token[-1],\n",
    "#         'suffix-2': token[-2:],\n",
    "#         'suffix-3': token[-3:],\n",
    "        #extracting previous token\n",
    "        'prev_token': '' if i == 0 else adress[i-1],\n",
    "        #extracting next token\n",
    "        'next_token': '' if i == len(adress)-1 else adress[i+1],\n",
    "        'has_hyphen': '-' in token, #if token has hypen\n",
    "        'is_numeric': token.isdigit(), #if token is in numeric\n",
    "    }\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "c5643f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_adress(adress, labels):\n",
    "    X_adress = []\n",
    "    y_adress = []\n",
    "    labels = labels.split()\n",
    "    elts = adress.split(\"<>\")\n",
    "    k=0\n",
    "    for i, elt in enumerate(elts):\n",
    "        tokens = elt.split()\n",
    "        for j, t in enumerate(tokens):\n",
    "            X_adress.append(token_features(adress.replace(\"<>\", \" \").split(), k))\n",
    "            y_adress.append(labels[i])\n",
    "            k+=1\n",
    "    return X_adress, y_adress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "241d13cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 1440190/1440190 [00:52<00:00, 27389.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# Extract features for each sentence in the corpus\n",
    "X = []\n",
    "y = []\n",
    "for i in tqdm(corpus.index):\n",
    "    X_adress, y_adress = process_adress(corpus_adr[i], corpus_lab[i])\n",
    "    X.append(X_adress)\n",
    "    y.append(y_adress)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "split = int(0.8 * len(X))\n",
    "X_train = X[:split]\n",
    "y_train = y[:split]\n",
    "X_test = X[split:]\n",
    "y_test = y[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796e1041",
   "metadata": {},
   "source": [
    "### entraînement / évaluation modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7289ea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "ff954f2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|██████████████████████████████████| 1152152/1152152 [01:09<00:00, 16476.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 517163\n",
      "Seconds required: 13.122\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.100000\n",
      "c2: 0.100000\n",
      "num_memories: 6\n",
      "max_iterations: 100\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=13.33 loss=10244522.85 active=509848 feature_norm=0.50\n",
      "Iter 2   time=4.57  loss=9184981.91 active=503081 feature_norm=0.42\n",
      "Iter 3   time=4.46  loss=8946855.00 active=510060 feature_norm=0.39\n",
      "Iter 4   time=4.45  loss=8639884.50 active=504384 feature_norm=0.40\n",
      "Iter 5   time=4.47  loss=8056028.58 active=510033 feature_norm=0.58\n",
      "Iter 6   time=4.47  loss=2541816.05 active=512451 feature_norm=4.73\n",
      "Iter 7   time=4.94  loss=2011539.62 active=501597 feature_norm=5.74\n",
      "Iter 8   time=4.99  loss=1661149.47 active=507309 feature_norm=7.44\n",
      "Iter 9   time=4.97  loss=1427203.36 active=511185 feature_norm=8.60\n",
      "Iter 10  time=5.00  loss=1331697.99 active=513809 feature_norm=9.31\n",
      "Iter 11  time=4.80  loss=1212274.03 active=512991 feature_norm=10.68\n",
      "Iter 12  time=4.90  loss=1144313.54 active=513347 feature_norm=11.31\n",
      "Iter 13  time=4.85  loss=997888.15 active=508956 feature_norm=13.81\n",
      "Iter 14  time=5.16  loss=916024.30 active=506006 feature_norm=16.74\n",
      "Iter 15  time=5.12  loss=869093.77 active=503647 feature_norm=20.99\n",
      "Iter 16  time=4.65  loss=823345.95 active=502822 feature_norm=22.56\n",
      "Iter 17  time=4.89  loss=784628.61 active=495648 feature_norm=25.97\n",
      "Iter 18  time=5.27  loss=746320.67 active=487583 feature_norm=31.10\n",
      "Iter 19  time=5.19  loss=708332.19 active=484085 feature_norm=34.74\n",
      "Iter 20  time=4.77  loss=677643.10 active=476980 feature_norm=36.87\n",
      "Iter 21  time=4.51  loss=643073.89 active=447816 feature_norm=39.78\n",
      "Iter 22  time=4.40  loss=611845.98 active=421886 feature_norm=42.13\n",
      "Iter 23  time=4.41  loss=582148.87 active=411918 feature_norm=45.01\n",
      "Iter 24  time=4.47  loss=554344.54 active=399333 feature_norm=48.12\n",
      "Iter 25  time=5.53  loss=522308.53 active=393822 feature_norm=52.91\n",
      "Iter 26  time=4.59  loss=491769.61 active=387168 feature_norm=59.63\n",
      "Iter 27  time=4.41  loss=460849.15 active=379352 feature_norm=64.54\n",
      "Iter 28  time=4.39  loss=426396.97 active=352751 feature_norm=71.30\n",
      "Iter 29  time=4.41  loss=392746.19 active=338841 feature_norm=79.99\n",
      "Iter 30  time=4.44  loss=361914.19 active=337845 feature_norm=89.48\n",
      "Iter 31  time=4.44  loss=335843.92 active=337048 feature_norm=99.29\n",
      "Iter 32  time=4.45  loss=312340.02 active=336805 feature_norm=110.01\n",
      "Iter 33  time=4.48  loss=287166.42 active=336525 feature_norm=121.27\n",
      "Iter 34  time=4.71  loss=260982.58 active=335536 feature_norm=138.23\n",
      "Iter 35  time=4.72  loss=238037.17 active=335061 feature_norm=152.54\n",
      "Iter 36  time=4.90  loss=220806.90 active=324735 feature_norm=169.66\n",
      "Iter 37  time=31.70 loss=220404.03 active=325552 feature_norm=169.92\n",
      "Iter 38  time=4.49  loss=209474.08 active=313380 feature_norm=177.83\n",
      "Iter 39  time=4.42  loss=193957.69 active=293067 feature_norm=197.41\n",
      "Iter 40  time=4.47  loss=181879.53 active=283713 feature_norm=211.45\n",
      "Iter 41  time=4.50  loss=171456.94 active=268068 feature_norm=223.91\n",
      "Iter 42  time=4.45  loss=158854.30 active=250648 feature_norm=243.86\n",
      "Iter 43  time=4.43  loss=148881.96 active=238259 feature_norm=258.63\n",
      "Iter 44  time=4.42  loss=140134.12 active=231410 feature_norm=271.08\n",
      "Iter 45  time=4.47  loss=131948.61 active=228035 feature_norm=286.07\n",
      "Iter 46  time=4.41  loss=125213.79 active=225715 feature_norm=296.10\n",
      "Iter 47  time=4.44  loss=118979.69 active=219838 feature_norm=308.86\n",
      "Iter 48  time=4.58  loss=113319.90 active=218153 feature_norm=320.29\n",
      "Iter 49  time=4.80  loss=109107.00 active=211341 feature_norm=330.93\n",
      "Iter 50  time=4.81  loss=105646.39 active=202338 feature_norm=340.01\n",
      "Iter 51  time=4.84  loss=102324.17 active=200727 feature_norm=350.25\n",
      "Iter 52  time=4.75  loss=99643.90 active=193246 feature_norm=356.55\n",
      "Iter 53  time=4.93  loss=97004.00 active=186848 feature_norm=365.17\n",
      "Iter 54  time=4.40  loss=95245.38 active=185178 feature_norm=367.91\n",
      "Iter 55  time=4.41  loss=93332.24 active=182601 feature_norm=372.78\n",
      "Iter 56  time=4.42  loss=91439.39 active=175468 feature_norm=377.74\n",
      "Iter 57  time=4.37  loss=89700.79 active=171179 feature_norm=380.65\n",
      "Iter 58  time=4.44  loss=88021.99 active=168982 feature_norm=385.46\n",
      "Iter 59  time=8.87  loss=87392.97 active=166543 feature_norm=380.25\n",
      "Iter 60  time=4.42  loss=86428.81 active=163730 feature_norm=383.14\n",
      "Iter 61  time=4.49  loss=85471.24 active=161152 feature_norm=385.44\n",
      "Iter 62  time=4.52  loss=83842.60 active=157344 feature_norm=387.24\n",
      "Iter 63  time=4.63  loss=82735.41 active=157086 feature_norm=391.10\n",
      "Iter 64  time=5.08  loss=81731.14 active=155862 feature_norm=392.53\n",
      "Iter 65  time=4.51  loss=80324.39 active=152190 feature_norm=394.06\n",
      "Iter 66  time=4.49  loss=79424.28 active=150064 feature_norm=395.72\n",
      "Iter 67  time=4.40  loss=78386.82 active=149251 feature_norm=396.14\n",
      "Iter 68  time=4.52  loss=77282.65 active=147033 feature_norm=397.23\n",
      "Iter 69  time=4.63  loss=76754.50 active=145375 feature_norm=394.06\n",
      "Iter 70  time=4.88  loss=76014.57 active=145211 feature_norm=395.45\n",
      "Iter 71  time=4.41  loss=75502.43 active=144595 feature_norm=395.77\n",
      "Iter 72  time=4.45  loss=74661.69 active=143102 feature_norm=396.17\n",
      "Iter 73  time=4.45  loss=74321.87 active=142584 feature_norm=398.48\n",
      "Iter 74  time=4.39  loss=73719.75 active=142566 feature_norm=398.29\n",
      "Iter 75  time=4.36  loss=73309.86 active=141495 feature_norm=398.76\n",
      "Iter 76  time=4.39  loss=72829.90 active=139377 feature_norm=400.37\n",
      "Iter 77  time=4.41  loss=72525.77 active=138305 feature_norm=401.23\n",
      "Iter 78  time=4.38  loss=72098.05 active=137971 feature_norm=402.39\n",
      "Iter 79  time=4.45  loss=71767.30 active=137617 feature_norm=402.81\n",
      "Iter 80  time=4.89  loss=71321.02 active=135963 feature_norm=403.77\n",
      "Iter 81  time=9.34  loss=71125.83 active=136021 feature_norm=404.05\n",
      "Iter 82  time=4.62  loss=70868.83 active=135638 feature_norm=404.61\n",
      "Iter 83  time=4.82  loss=70548.06 active=135009 feature_norm=404.96\n",
      "Iter 84  time=4.39  loss=70230.58 active=134216 feature_norm=405.20\n",
      "Iter 85  time=4.48  loss=69956.21 active=133571 feature_norm=405.31\n",
      "Iter 86  time=4.59  loss=69721.34 active=133022 feature_norm=405.64\n",
      "Iter 87  time=4.48  loss=69509.17 active=131003 feature_norm=405.78\n",
      "Iter 88  time=4.52  loss=69302.39 active=130367 feature_norm=406.16\n",
      "Iter 89  time=4.54  loss=69089.02 active=129509 feature_norm=406.46\n",
      "Iter 90  time=4.45  loss=68910.48 active=128769 feature_norm=406.75\n",
      "Iter 91  time=4.76  loss=68733.38 active=128089 feature_norm=406.89\n",
      "Iter 92  time=4.93  loss=68575.33 active=127677 feature_norm=407.16\n",
      "Iter 93  time=4.44  loss=68429.55 active=126810 feature_norm=407.30\n",
      "Iter 94  time=4.46  loss=68306.55 active=126438 feature_norm=407.58\n",
      "Iter 95  time=4.44  loss=68180.10 active=126050 feature_norm=407.59\n",
      "Iter 96  time=4.51  loss=68050.59 active=125242 feature_norm=407.78\n",
      "Iter 97  time=4.43  loss=67937.91 active=124335 feature_norm=407.84\n",
      "Iter 98  time=4.50  loss=67825.75 active=123999 feature_norm=408.04\n",
      "Iter 99  time=4.98  loss=67723.08 active=123708 feature_norm=408.13\n",
      "Iter 100 time=4.56  loss=67632.43 active=123265 feature_norm=408.28\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 505.773\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 123265 (517163)\n",
      "Number of active attributes: 81440 (392098)\n",
      "Number of active labels: 4 (4)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.303\n",
      "\n",
      "0.9966955423949748\n"
     ]
    }
   ],
   "source": [
    "# Train a CRF model on the training data\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True,\n",
    "    verbose=True\n",
    ")\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data and evaluate the performance\n",
    "y_pred = crf.predict(X_test)\n",
    "\n",
    "print(metrics.flat_accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6ccbce",
   "metadata": {},
   "source": [
    "### predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "1c2f5add",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "def predict(adress):\n",
    "    print(adress)\n",
    "    X_adress = []\n",
    "    tokens = adress.split()\n",
    "    for i in range(len(tokens)):\n",
    "        X_adress.append(token_features(tokens, i))\n",
    "    tags = crf.predict([X_adress]).tolist()[0]\n",
    "    pprint(list(zip(tokens, tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "91fb262f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 CALLE LA FUENTE (BA) 42318 BARCEBAL\n",
      "[('21', 'num'),\n",
      " ('CALLE', 'rue'),\n",
      " ('LA', 'rue'),\n",
      " ('FUENTE', 'rue'),\n",
      " ('(BA)', 'rue'),\n",
      " ('42318', 'cp'),\n",
      " ('BARCEBAL', 'ville')]\n"
     ]
    }
   ],
   "source": [
    "predict(corpus_adr.iloc[-537].replace(\"<>\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71206593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test[-537]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f602ca9e",
   "metadata": {},
   "source": [
    "## NER-like approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e74ceead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(i, j, tokens, labels):\n",
    "    if len(tokens)==1:\n",
    "        return \"U-\"+labels[i]\n",
    "    else:\n",
    "        if j==0:\n",
    "            return \"B-\"+labels[i]\n",
    "        elif j==(len(tokens)-1):\n",
    "            return \"L-\"+labels[i]\n",
    "        else:\n",
    "            return \"I-\"+labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "12a41ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_adress_ner(adress, labels):\n",
    "    X_adress = []\n",
    "    y_adress = []\n",
    "    labels = labels.split()\n",
    "    elts = adress.split(\"<>\")\n",
    "    k=0\n",
    "    for i, elt in enumerate(elts):\n",
    "        tokens = elt.split()\n",
    "        for j, t in enumerate(tokens):\n",
    "            X_adress.append(token_features(adress.replace(\"<>\", \" \").split(), k))\n",
    "            y_adress.append(get_label(i, j, tokens, labels))\n",
    "            k+=1\n",
    "    return X_adress, y_adress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fce182d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 1440190/1440190 [00:53<00:00, 26775.67it/s]\n"
     ]
    }
   ],
   "source": [
    "# Extract features for each sentence in the corpus\n",
    "X = []\n",
    "y = []\n",
    "for i in tqdm(corpus.index):\n",
    "    X_adress, y_adress = process_adress_ner(corpus_adr[i], corpus_lab[i])\n",
    "    X.append(X_adress)\n",
    "    y.append(y_adress)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "split = int(0.8 * len(X))\n",
    "X_train = X[:split]\n",
    "y_train = y[:split]\n",
    "X_test = X[split:]\n",
    "y_test = y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b405eda0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|██████████████████████████████████| 1152152/1152152 [01:02<00:00, 18537.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 617526\n",
      "Seconds required: 14.385\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.100000\n",
      "c2: 0.100000\n",
      "num_memories: 6\n",
      "max_iterations: 100\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=26.04 loss=16334130.89 active=614439 feature_norm=0.50\n",
      "Iter 2   time=8.42  loss=15788777.15 active=605152 feature_norm=0.51\n",
      "Iter 3   time=8.77  loss=15421342.66 active=611351 feature_norm=0.57\n",
      "Iter 4   time=8.50  loss=10950281.70 active=607588 feature_norm=2.41\n",
      "Iter 5   time=9.05  loss=5141157.97 active=611554 feature_norm=7.93\n",
      "Iter 6   time=26.78 loss=4666964.67 active=613922 feature_norm=8.69\n",
      "Iter 7   time=8.79  loss=3716686.65 active=615546 feature_norm=9.78\n",
      "Iter 8   time=9.07  loss=2964209.45 active=615274 feature_norm=11.92\n",
      "Iter 9   time=8.80  loss=2208178.96 active=613345 feature_norm=14.65\n",
      "Iter 10  time=8.61  loss=1602216.30 active=614495 feature_norm=18.08\n",
      "Iter 11  time=8.74  loss=1318861.43 active=614670 feature_norm=20.29\n",
      "Iter 12  time=8.47  loss=1112986.09 active=613547 feature_norm=23.25\n",
      "Iter 13  time=8.04  loss=978526.53 active=614777 feature_norm=24.87\n",
      "Iter 14  time=8.28  loss=874192.85 active=614893 feature_norm=26.72\n",
      "Iter 15  time=8.21  loss=750433.08 active=613282 feature_norm=29.27\n",
      "Iter 16  time=8.29  loss=670244.25 active=611140 feature_norm=33.59\n",
      "Iter 17  time=8.09  loss=606936.96 active=611044 feature_norm=36.08\n",
      "Iter 18  time=8.19  loss=569545.47 active=608636 feature_norm=39.81\n",
      "Iter 19  time=8.19  loss=539133.54 active=608262 feature_norm=43.38\n",
      "Iter 20  time=8.11  loss=513500.43 active=605435 feature_norm=47.10\n",
      "Iter 21  time=8.14  loss=492717.92 active=598267 feature_norm=50.55\n",
      "Iter 22  time=8.32  loss=476491.95 active=587399 feature_norm=53.72\n",
      "Iter 23  time=8.29  loss=457335.83 active=584501 feature_norm=57.18\n",
      "Iter 24  time=8.26  loss=440704.83 active=566012 feature_norm=61.33\n",
      "Iter 25  time=8.24  loss=426146.93 active=556599 feature_norm=65.60\n",
      "Iter 26  time=8.20  loss=408847.20 active=553731 feature_norm=69.23\n",
      "Iter 27  time=8.26  loss=394246.47 active=549945 feature_norm=72.90\n",
      "Iter 28  time=8.27  loss=380147.52 active=535961 feature_norm=76.24\n",
      "Iter 29  time=8.36  loss=365094.01 active=526420 feature_norm=80.27\n",
      "Iter 30  time=8.23  loss=347496.60 active=509129 feature_norm=82.50\n",
      "Iter 31  time=8.10  loss=331205.09 active=492891 feature_norm=86.08\n",
      "Iter 32  time=8.05  loss=311573.71 active=485194 feature_norm=88.83\n",
      "Iter 33  time=8.05  loss=292232.90 active=482754 feature_norm=92.55\n",
      "Iter 34  time=8.08  loss=272849.53 active=478233 feature_norm=95.83\n",
      "Iter 35  time=7.97  loss=250779.78 active=474337 feature_norm=100.46\n",
      "Iter 36  time=7.98  loss=230292.29 active=468207 feature_norm=106.47\n",
      "Iter 37  time=8.07  loss=206801.43 active=462438 feature_norm=114.42\n",
      "Iter 38  time=8.19  loss=185406.78 active=450859 feature_norm=123.99\n",
      "Iter 39  time=50.09 loss=184593.88 active=451121 feature_norm=124.50\n",
      "Iter 40  time=9.00  loss=161325.14 active=431589 feature_norm=138.85\n",
      "Iter 41  time=8.02  loss=143666.93 active=416886 feature_norm=154.21\n",
      "Iter 42  time=7.99  loss=131288.69 active=391755 feature_norm=165.02\n",
      "Iter 43  time=8.02  loss=119569.05 active=375188 feature_norm=178.27\n",
      "Iter 44  time=7.98  loss=107719.21 active=361271 feature_norm=194.03\n",
      "Iter 45  time=8.03  loss=100099.92 active=356042 feature_norm=202.08\n",
      "Iter 46  time=7.94  loss=90024.78 active=343872 feature_norm=218.68\n",
      "Iter 47  time=16.15 loss=88188.65 active=333114 feature_norm=229.59\n",
      "Iter 48  time=8.17  loss=80623.56 active=323107 feature_norm=239.20\n",
      "Iter 49  time=7.98  loss=75838.03 active=304754 feature_norm=249.65\n",
      "Iter 50  time=7.96  loss=70315.37 active=298453 feature_norm=263.87\n",
      "Iter 51  time=7.99  loss=68100.68 active=286988 feature_norm=280.55\n",
      "Iter 52  time=8.01  loss=64121.52 active=287878 feature_norm=281.57\n",
      "Iter 53  time=8.02  loss=62355.53 active=283754 feature_norm=283.67\n",
      "Iter 54  time=7.97  loss=59632.01 active=266339 feature_norm=289.36\n",
      "Iter 55  time=8.56  loss=58892.61 active=258418 feature_norm=305.08\n",
      "Iter 56  time=8.26  loss=55049.53 active=259325 feature_norm=302.19\n",
      "Iter 57  time=8.11  loss=54141.28 active=252709 feature_norm=303.30\n",
      "Iter 58  time=8.26  loss=51881.31 active=248490 feature_norm=309.59\n",
      "Iter 59  time=16.13 loss=51723.84 active=242710 feature_norm=311.21\n",
      "Iter 60  time=8.05  loss=50285.80 active=242541 feature_norm=311.68\n",
      "Iter 61  time=8.12  loss=49450.52 active=235406 feature_norm=312.72\n",
      "Iter 62  time=8.43  loss=48084.32 active=223199 feature_norm=316.18\n",
      "Iter 63  time=8.16  loss=47600.42 active=215671 feature_norm=317.85\n",
      "Iter 64  time=8.24  loss=46612.48 active=216161 feature_norm=319.05\n",
      "Iter 65  time=8.22  loss=46066.55 active=214421 feature_norm=319.82\n",
      "Iter 66  time=8.29  loss=44980.41 active=210215 feature_norm=321.09\n",
      "Iter 67  time=24.62 loss=44823.31 active=208576 feature_norm=322.19\n",
      "Iter 68  time=8.33  loss=44123.36 active=205252 feature_norm=322.14\n",
      "Iter 69  time=8.09  loss=43545.42 active=201013 feature_norm=322.89\n",
      "Iter 70  time=8.14  loss=42900.29 active=195240 feature_norm=324.54\n",
      "Iter 71  time=16.53 loss=42592.81 active=191902 feature_norm=325.67\n",
      "Iter 72  time=8.42  loss=42093.68 active=188882 feature_norm=326.79\n",
      "Iter 73  time=8.15  loss=41606.98 active=184363 feature_norm=327.66\n",
      "Iter 74  time=8.30  loss=41190.35 active=180508 feature_norm=328.19\n",
      "Iter 75  time=8.14  loss=40787.47 active=178731 feature_norm=328.30\n",
      "Iter 76  time=8.16  loss=40349.44 active=176039 feature_norm=328.82\n",
      "Iter 77  time=8.07  loss=39990.19 active=173803 feature_norm=329.80\n",
      "Iter 78  time=8.32  loss=39650.64 active=172589 feature_norm=330.34\n",
      "Iter 79  time=8.25  loss=39293.07 active=170175 feature_norm=331.27\n",
      "Iter 80  time=8.04  loss=39091.29 active=168100 feature_norm=332.33\n",
      "Iter 81  time=8.33  loss=38796.94 active=168190 feature_norm=332.62\n",
      "Iter 82  time=8.27  loss=38599.56 active=167563 feature_norm=332.90\n",
      "Iter 83  time=8.36  loss=38335.36 active=165957 feature_norm=333.47\n",
      "Iter 84  time=8.25  loss=38132.02 active=165507 feature_norm=333.58\n",
      "Iter 85  time=8.21  loss=37918.49 active=164354 feature_norm=333.74\n",
      "Iter 86  time=8.35  loss=37650.79 active=162390 feature_norm=333.96\n",
      "Iter 87  time=8.01  loss=37458.65 active=161340 feature_norm=334.14\n",
      "Iter 88  time=8.07  loss=37296.16 active=160342 feature_norm=334.25\n",
      "Iter 89  time=8.27  loss=37133.50 active=159908 feature_norm=334.38\n",
      "Iter 90  time=8.06  loss=36974.14 active=158133 feature_norm=334.47\n",
      "Iter 91  time=8.18  loss=36841.45 active=157173 feature_norm=334.49\n",
      "Iter 92  time=8.12  loss=36730.49 active=155856 feature_norm=334.51\n",
      "Iter 93  time=8.08  loss=36615.90 active=155019 feature_norm=334.46\n",
      "Iter 94  time=8.11  loss=36514.84 active=154358 feature_norm=334.38\n",
      "Iter 95  time=8.01  loss=36426.62 active=153601 feature_norm=334.29\n",
      "Iter 96  time=8.06  loss=36345.04 active=152173 feature_norm=334.17\n",
      "Iter 97  time=8.05  loss=36271.17 active=151413 feature_norm=334.12\n",
      "Iter 98  time=7.96  loss=36198.15 active=150977 feature_norm=333.92\n",
      "Iter 99  time=8.12  loss=36127.94 active=149891 feature_norm=333.77\n",
      "Iter 100 time=8.29  loss=36051.00 active=148927 feature_norm=333.50\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 941.377\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 148927 (617526)\n",
      "Number of active attributes: 91681 (392180)\n",
      "Number of active labels: 9 (9)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.338\n",
      "\n",
      "0.9969771531883543\n"
     ]
    }
   ],
   "source": [
    "# Train a CRF model on the training data\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True,\n",
    "    verbose=True\n",
    ")\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data and evaluate the performance\n",
    "y_pred = crf.predict(X_test)\n",
    "\n",
    "print(metrics.flat_accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3af5ac",
   "metadata": {},
   "source": [
    "## Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2d38bd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "41217948",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichiers dans l'archive ZIP :\n",
      "['LIST', 'meta.json', 'model.bin', 'model.txt', 'README']\n",
      "\n",
      "Contenu du fichier LIST :\n",
      "b'es-common_crawl-257\\n'\n",
      "b'es-common_crawl-328\\n'\n",
      "b'es-common_crawl-119\\n'\n",
      "b'es-common_crawl-199\\n'\n",
      "b'es-common_crawl-172\\n'\n",
      "b'es-common_crawl-141\\n'\n",
      "b'es-common_crawl-017\\n'\n",
      "b'es-common_crawl-296\\n'\n",
      "b'es-common_crawl-330\\n'\n",
      "b'es-common_crawl-350\\n'\n",
      "b'es-common_crawl-046\\n'\n",
      "b'es-common_crawl-189\\n'\n",
      "b'es-common_crawl-077\\n'\n",
      "b'es-common_crawl-059\\n'\n",
      "b'es-common_crawl-102\\n'\n",
      "b'es-common_crawl-084\\n'\n",
      "b'es-common_crawl-283\\n'\n",
      "b'es-common_crawl-204\\n'\n",
      "b'es-wikipedia-013\\n'\n",
      "b'es-common_crawl-312\\n'\n",
      "b'es-common_crawl-343\\n'\n",
      "b'es-common_crawl-074\\n'\n",
      "b'es-common_crawl-249\\n'\n",
      "b'es-common_crawl-342\\n'\n",
      "b'es-common_crawl-377\\n'\n",
      "b'es-common_crawl-033\\n'\n",
      "b'es-common_crawl-022\\n'\n",
      "b'es-common_crawl-006\\n'\n",
      "b'es-common_crawl-365\\n'\n",
      "b'es-common_crawl-062\\n'\n",
      "b'es-common_crawl-336\\n'\n",
      "b'es-common_crawl-166\\n'\n",
      "b'es-common_crawl-021\\n'\n",
      "b'es-common_crawl-383\\n'\n",
      "b'es-wikipedia-015\\n'\n",
      "b'es-wikipedia-017\\n'\n",
      "b'es-common_crawl-313\\n'\n",
      "b'es-common_crawl-231\\n'\n",
      "b'es-common_crawl-224\\n'\n",
      "b'es-common_crawl-247\\n'\n",
      "b'es-common_crawl-103\\n'\n",
      "b'es-common_crawl-223\\n'\n",
      "b'es-common_crawl-090\\n'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[137], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m#                 print(fichier.read().decode('utf-8'))  # Décodage en fonction du type de fichier\u001b[39;00m\n\u001b[0;32m     35\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m fichier:\n\u001b[1;32m---> 36\u001b[0m                     \u001b[38;5;28mprint\u001b[39m(line); sleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mErreur \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m lors de la récupération du fichier ZIP\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "# URL du fichier ZIP en ligne\n",
    "url = 'http://vectors.nlpl.eu/repository/20/68.zip' # lowercased\n",
    "\n",
    "# Faire une requête GET en mode streaming\n",
    "response = requests.get(url, stream=True)\n",
    "\n",
    "# Vérifier que la requête a réussi\n",
    "if response.status_code == 200:\n",
    "    # Utiliser un objet BytesIO pour charger le contenu du fichier ZIP dans un flux en mémoire\n",
    "    fichier_zip = io.BytesIO()\n",
    "\n",
    "    # Lire et écrire les chunks dans le flux en mémoire\n",
    "    for chunk in response.iter_content(chunk_size=1024):\n",
    "        fichier_zip.write(chunk)\n",
    "\n",
    "    # Remettre le pointeur du flux en début\n",
    "    fichier_zip.seek(0)\n",
    "else:\n",
    "    print(f\"Erreur {response.status_code} lors de la récupération du fichier ZIP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b62cdb69",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"algorithm\": {\n",
      "        \"command\": \"word2vec -min-count 10 -size 100 -window 10 -negative 5 -iter 2 -threads 16 -cbow 0 -binary 0\",\n",
      "        \"id\": 3,\n",
      "        \"name\": \"Word2Vec Continuous Skipgram\",\n",
      "        \"tool\": \"word2vec\",\n",
      "        \"url\": \"https://code.google.com/archive/p/word2vec/\",\n",
      "        \"version\": null\n",
      "    },\n",
      "    \"contents\": [\n",
      "        {\n",
      "            \"filename\": \"model.txt\",\n",
      "            \"format\": \"text\"\n",
      "        },\n",
      "        {\n",
      "            \"filename\": \"meta.json\",\n",
      "            \"format\": \"json\"\n",
      "        },\n",
      "        {\n",
      "            \"filename\": \"LIST\",\n",
      "            \"format\": \"text\"\n",
      "        }\n",
      "    ],\n",
      "    \"corpus\": [\n",
      "        {\n",
      "            \"NER\": false,\n",
      "            \"case preserved\": false,\n",
      "            \"description\": \"Spanish CoNLL17 corpus\",\n",
      "            \"id\": 68,\n",
      "            \"language\": \"spa\",\n",
      "            \"lemmatized\": false,\n",
      "            \"public\": true,\n",
      "            \"stop words removal\": null,\n",
      "            \"tagger\": null,\n",
      "            \"tagset\": null,\n",
      "            \"tokens\": 5967877096,\n",
      "            \"tool\": null,\n",
      "            \"url\": null\n",
      "        }\n",
      "    ],\n",
      "    \"creators\": [\n",
      "        {\n",
      "            \"email\": \"andreku@ifi.uio.no\",\n",
      "            \"name\": \"Andrey Kutuzov\"\n",
      "        }\n",
      "    ],\n",
      "    \"dimensions\": 100,\n",
      "    \"handle\": \"http://vectors.nlpl.eu/repository/20/68.zip\",\n",
      "    \"id\": 68,\n",
      "    \"iterations\": 2,\n",
      "    \"vocabulary size\": 2656057,\n",
      "    \"window\": 10\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Embeddings metadata\n",
    "with zipfile.ZipFile(fichier_zip, 'r') as archive_zip:\n",
    "    with archive_zip.open(\"meta.json\") as fichier:\n",
    "        print(fichier.read().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "aac66e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d43cef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4904d704",
   "metadata": {},
   "outputs": [],
   "source": [
    "errs=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "2797b131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichiers dans l'archive ZIP :\n",
      "['LIST', 'meta.json', 'model.bin', 'model.txt', 'README']\n",
      "\n",
      "Contenu du fichier model.txt :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2656057it [02:54, 15254.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# Ouvrir le fichier ZIP directement depuis le flux en mémoire\n",
    "with zipfile.ZipFile(fichier_zip, 'r') as archive_zip:\n",
    "    # Lister les fichiers dans l'archive ZIP\n",
    "    print(\"Fichiers dans l'archive ZIP :\")\n",
    "    print(archive_zip.namelist())\n",
    "\n",
    "    # Extraire et lire chaque fichier dans l'archive sans tout charger en mémoire\n",
    "    for file_name in archive_zip.namelist():\n",
    "        with archive_zip.open(file_name) as fichier:\n",
    "            if file_name==\"model.txt\":\n",
    "                # Lire et afficher le contenu de chaque fichier dans l'archive\n",
    "                print(f\"\\nContenu du fichier {file_name} :\")\n",
    "                fichier.readline()\n",
    "                for line in tqdm(fichier):\n",
    "                    try:\n",
    "                        line = line.decode().split()\n",
    "                        embeddings[line[0]] = np.array(line[1:], dtype=float)\n",
    "                    except UnicodeDecodeError:\n",
    "                        errs.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "6f9742af",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "for w in embeddings:\n",
    "    if w.isalpha() and not w.islower():\n",
    "        a.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "8610a28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2656037"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "94f4e42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "a08b32c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lex in nlp.vocab:\n",
    "    vocab.add(lex.text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "9fc4a98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15656"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "66be4632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['benalmadena', '03740', 'vizcaino', '39700', 'vargas']"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vocab)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "3a59cdea",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.074875, -0.298918, -0.039462, -0.405561,  0.140007, -0.793524,\n",
       "       -0.569674,  0.066463,  0.222174,  0.567297,  0.768356, -0.102119,\n",
       "        0.030638, -0.270314,  0.231208,  0.261223,  1.453737,  0.388108,\n",
       "       -0.034544,  0.334545,  0.419761,  0.639755, -0.386967, -0.618236,\n",
       "       -0.207673,  0.163131, -0.091391,  0.117188,  0.748305, -0.600575,\n",
       "       -0.298912, -0.909222, -0.260297,  0.245753, -0.625691,  0.492283,\n",
       "        1.000935,  0.807789,  0.598377, -0.469359,  0.37331 ,  0.266725,\n",
       "       -0.378582,  0.228711,  1.350615,  0.131113,  0.602769,  0.178402,\n",
       "       -0.610236, -0.340824, -0.267198,  0.535875,  0.122946, -0.261453,\n",
       "        0.262169, -0.313327,  0.616017, -0.241744,  0.040091, -0.279985,\n",
       "        0.715574, -0.012725,  0.153394,  0.163833,  0.043303,  0.741668,\n",
       "        0.098392,  0.253791,  0.446562,  0.425529,  0.043278, -0.14111 ,\n",
       "        0.318389, -0.325201,  0.233115, -0.56962 ,  0.242946, -0.405108,\n",
       "       -0.128333,  0.431896,  0.615846,  0.354486, -0.185486, -0.447206,\n",
       "        0.748941,  0.47887 , -0.622434, -0.404748, -0.30804 , -0.205711,\n",
       "       -0.206183,  1.109963,  0.152504, -0.206575,  0.128196, -0.887939,\n",
       "       -0.153776, -0.825289,  0.128771,  0.153171])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[\"benalmadena\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "5ca3ede2",
   "metadata": {},
   "outputs": [],
   "source": [
    "oov=set()\n",
    "for w in vocab:\n",
    "    if w not in embeddings:\n",
    "        oov.add(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "4be06096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2786"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "2449c5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coiñas', 'llavanera', 'puigfarners', 'esfiliana', '17181']"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(oov)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13707cd6",
   "metadata": {},
   "source": [
    "# Deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f73fad2",
   "metadata": {},
   "source": [
    "Le problème de parsing d'adresses postales peut se rapprocher d'un problème de reconnaissance d'entités nommées (NER). Il s'agit de classifier une séquence de tokens en sachant qu'une catégorie d'une adresse postale - le nom de la rue, par exemple - peut s'étendre sur plusieurs tokens. Il en est de même pour les entités nommées. Par exemple un nom de personne s'étendra souvent sur 2 tokens ou plus (nom et prénom).  \n",
    "  \n",
    "Spacy est une libairie performante pour le problème de reconnaissance des entités nommées. C'est une librairie \"high-level\" basée sur des réseaux de neurones. C'est cette solution que j'ai choisi pour la partie deep learning de résolution du usecase. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6126af3a",
   "metadata": {},
   "source": [
    "### Librairie Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3489c761",
   "metadata": {},
   "source": [
    "L'architecture est composée d'une couche d'embeddings suivie de réseaux convolutifs pour capturer le contexte. L'output sert à prédire la prochaine action à effectuer dans un algorithme de parsing séquentiel de type shift-reduce.  \n",
    "  \n",
    "L'inconvénient de cette librairie est son opacité. Il semble par exemple difficile d'accéder aux vecteurs contextuels des mots. De même, il est difficile d'accéder aux features utilisés à l'étape finale de prédiction. Ceux-ci sont malgré tout présentés dans une vidéo du fondateur de Spacy et sont les suivants:  \n",
    "mot courant, mot précédant, mot suivant; premier et dernier mot de l'entité précédente, dernier mot de l'entité encore avant  \n",
    "Il n'est pas clair si ces features sont personnalisables ou non, même si cela semble probable étant donné que cette flexibilité est mise en avant comme un des atouts de leur solution.  \n",
    "  \n",
    "Concernant les embeddings, il est possible de charger des embeddings pré-entraînés. De même, il est possible de changer leur architecture à base de CNN par une architecture de type transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb956695",
   "metadata": {},
   "source": [
    "### Comparaison CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25508a84",
   "metadata": {},
   "source": [
    "Les résultats obtenus dans les mêmes conditions qu'avec les CRF plus haut sont largement supérieurs. Là où les CRF atteignent un f1-score de 0.86, le module NER de Spacy atteint un score au-delà de 0.99. Cela peut également laisser supposer un overfitting qui demande à être contrôlé en ajoutant de la variabilité dans les données de développement. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21711247",
   "metadata": {},
   "source": [
    "Le coût computationnel est bien entendu supérieur. Là où le CRF a pu réaliser 100 époques en 10 minutes, le module NER de Spacy a pris plusieurs heures pour réaliser une seule époque. A noter néanmoins la possibilité de basculer une partie des calculs sur le GPU pour améliorer les performances. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bdcf91",
   "metadata": {},
   "source": [
    "### Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22988690",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b0e375a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(raw_adress, raw_labels):\n",
    "    adress_parts = raw_adress.split(\"<>\")\n",
    "    labels = raw_labels.split()\n",
    "    labels_new = {\"entities\":[]}\n",
    "    left_bound = 0\n",
    "    for i, ap in enumerate(adress_parts):\n",
    "        labels_new[\"entities\"].append((left_bound, left_bound+len(ap), labels[i]))\n",
    "        left_bound += len(ap)+1\n",
    "    return (raw_adress.replace(\"<>\", \" \"), labels_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "16dfb618",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 47782.82it/s]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for i in tqdm(range(len(corpus_adr[:10000]))):\n",
    "    data.append(format_data(corpus_adr.iloc[i], corpus_lab.iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "52dac6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(len(data)*0.8)\n",
    "train_data = data[:split]\n",
    "test_data = data[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b488708",
   "metadata": {},
   "source": [
    "### Initialisation modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a4f61df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"es\")\n",
    "\n",
    "ner = nlp.add_pipe(\"ner\")\n",
    "\n",
    "for label in corpus_lab.iloc[0].split():\n",
    "    ner.add_label(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dc97c6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 8000/8000 [00:02<00:00, 2900.12it/s]\n"
     ]
    }
   ],
   "source": [
    "from spacy.training.example import Example\n",
    "\n",
    "for i in tqdm(range(len(train_data))):\n",
    "    text, labels = train_data[i]\n",
    "    doc = nlp.make_doc(text)\n",
    "    train_data[i] = Example.from_dict(doc, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bec987",
   "metadata": {},
   "source": [
    "### Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ab2d6bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:24, 10.05it/s]\n"
     ]
    }
   ],
   "source": [
    "from spacy.util import minibatch\n",
    "\n",
    "optimizer = nlp.begin_training()\n",
    "\n",
    "batches = minibatch(train_data, size=32)\n",
    "for batch in tqdm(batches):\n",
    "    nlp.update(batch, drop=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fe257d",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f86edaa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:00<00:00, 2925.95it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(test_data))):\n",
    "    text, labels = test_data[i]\n",
    "    doc = nlp.make_doc(text)\n",
    "    test_data[i] = Example.from_dict(doc, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "65e80278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_acc': 1.0,\n",
       " 'token_p': 1.0,\n",
       " 'token_r': 1.0,\n",
       " 'token_f': 1.0,\n",
       " 'ents_p': 0.9574328749181401,\n",
       " 'ents_r': 0.91375,\n",
       " 'ents_f': 0.935081547809402,\n",
       " 'ents_per_type': {'num': {'p': 0.998001998001998,\n",
       "   'r': 0.999,\n",
       "   'f': 0.9985007496251873},\n",
       "  'rue': {'p': 0.846382556987116, 'r': 0.854, 'f': 0.8501742160278746},\n",
       "  'cp': {'p': 0.998003992015968, 'r': 1.0, 'f': 0.9990009990009989},\n",
       "  'ville': {'p': 0.9956548727498448, 'r': 0.802, 'f': 0.8883965660481861}},\n",
       " 'speed': 9822.797372583555}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ae4b2df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "12 num\n",
      "CALLE GOYA VEREDA (LA) rue\n",
      "30300 cp\n",
      "\n",
      "0 num\n",
      "RONDA HOSPITAL rue\n",
      "27700 cp\n",
      "RIBADEO ville\n",
      "\n",
      "2 num\n",
      "CRRIL CIPRESES rue\n",
      "30139 cp\n",
      "HUERTA DEL RAAL ville\n",
      "\n",
      "77 num\n",
      "CARRE JOSEP NEBOT rue\n",
      "12540 cp\n",
      "\n",
      "CALLE BELICE-PUEBLO PRINCIPE rue\n",
      "1 num\n",
      "03189 cp\n",
      "ORIHUELA COSTA ville\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    doc = nlp(data[-i][0]); print()\n",
    "\n",
    "    # Parcourir les entités détectées\n",
    "    for ent in doc.ents:\n",
    "        print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "309e8493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp.to_disk(\"spacy_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uc",
   "language": "python",
   "name": "uc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
